[{"title":"Kong路径匹配算法总结","url":"/2022/08/21/Kong路由匹配规则总结/","content":"\n\n# 背景\n\n目前Kong一共支持两种路由规则`v0`及`v1`，这里指的路由规则是说当Kong接受到一个http请求之后会如何生成最终的请求url，这里简单总结下这两种规则的匹配逻辑，根据需求，可以按需使用\n\n\n# v0\n\n假设当前Kong有以下配置：\n```\n服务s：s.path = /service \n路由r: r.path = /route\n       r.strip_path = true\n上游u: u.target = https://google.com\n```\n\n如果当前请求url为`http://kong/route/foo`，当Kong接受到这个请求后首先可以判定这个请求命中了`路由r`，这个时候由于`路由r`有`router.strip_path = true`并且`路由r`对应的`服务s`有`service.path = /service `，那么最终生成的请求路径为：\n```\nhttps://google.com/service/foo\n```\n\n如果`路由r`有`r.strip_path=false`，那么最终生成的请求路径为：\n```\nhttps://google.com/service/route/foo\n```\n\n> 这里可以知道strip_path这个参数会影响到Kong是否会剥离路由定义的path\n\n\n# v1\n\n假设当前Kong有以下配置：\n```\n服务s：s.path = /service \n路由r: r.path = /route\n       r.strip_path = true\n上游u: u.target = https://google.com\n```\n如果当前请求url为`http://kong/route/foo`，当Kong接受到这个请求后首先可以判定这个请求命中了`路由r`，这个时候由于`路由r`有`router.strip_path = true`并且`路由r`对应的`服务s`有`service.path = /service `，那么最终生成的请求路径为：\n```\nhttps://google.com/service/foo\n```\n>这里可以看出当router.strip_path = true时，v0和v1算法的表现是一样的\n\n如果`路由r`有`r.strip_path=false`，那么最终生成的请求路径为：\n```\nhttps://google.com/serviceroute/foo\n```\n\n> 这里可以知道strip_path=false时，和v0有所不同，这里strip_path实际上时会将route.path的斜杠去掉后再将service.path与route.path拼接到一起"},{"title":"Kong网关CPU问题排查","url":"/2022/07/17/Kong网关 CPU问题排查/","content":"\n# 背景\n\n在Kong网关上线之前，公司原本是使用openresty作为所有业务的流量入口，qps 10w+，配置将近3000多条路由,其中大部分是正则路由。但是openresty的服务治理功能相对较弱，没有像Kong那样内置了大量开箱即用的插件，为了后续将一些服务治理的功能陆续迁移到网关层，如熔断，限流，决定使用Kong API网关对原有的Openresty进行替换，使用的版本是2.7.1\n\n在Kong网关上线后，其在CPU使用率上的不能让人满意，对该问题进行了排查并对此进行了优化\n\n\n# 问题纪录\n\nKong网关上线后，我们逐步的将生产环境的流量从openresty切换到Kong，最开始，CPU负载表现正常，如下图所示：\n![enter image description here](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/before.png)，每一个POD大概使用了0.4个核\n\n当我们开始将一些请求量大的接口切换到Kong网关上时，CPU占用率激增，从0.4核增加到了1.5核，一些POD CPU占用率更是达到了2.5核\n![enter image description here](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/after.png) \n\n\n为了解决CPU占用率过高的问题，首先我们使用火焰图找出当前Kong网关内部的一些调用热点：\n\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/max.svg)\n\n从上图可以看出，整个Kong网关的CPU都消耗在了正则匹配上。\n\n我们进一步排查发现，我们这些流量很大的接口实际上并没有用到正则表达式，而是一个简单的前缀匹配(开启strip_path)：\n\n```\n/foo\n```\n\n如上所示：当Kong拿到一个请求，如`http://bar.com/foo/xxxx`，那么这个时候Kong会将这个地址转化为`foo`对应的`upstream`,最终的URL为`http://foo-upstream/xxx`，进一步排查`Kong`源码，有如下发现，\n当Kong初始化内部的路由表时，会将所有正则路由存放到一个`regex_uris`中，所有前缀匹配的路由存放到`prefix_uris`:\n```lua\nlocal function index_route_t(route_t, plain_indexes, prefix_uris, regex_uris,\n                             wildcard_hosts, src_trust_funcs, dst_trust_funcs)\n   -- 省略不重要的代码\n  for _, uri_t in ipairs(route_t.uris) do\n    if uri_t.is_prefix then\n      plain_indexes.uris[uri_t.value] = true\n      insert(prefix_uris, uri_t)\n\n    else\n      insert(regex_uris, uri_t)\n    end\n  end\nend\n```\n\n当Kong收到一个请求的时候，需要判断这个请求是正则的路由还是前缀匹配的路由：\n\n```lua\n  local function find_route(req_method, req_uri, req_host, req_scheme,\n                            src_ip, src_port,\n                            dst_ip, dst_port,\n  )\n   -- 这里只截取关键代码\n    -- uri match\n\n    for i = 1, #regex_uris do\n      local from, _, err = re_find(req_uri, regex_uris[i].regex, \"ajo\")\n      if err then\n        log(ERR, \"could not evaluate URI regex: \", err)\n        return\n      end\n\n      if from then\n        hits.uri     = regex_uris[i].value\n        req_category = bor(req_category, MATCH_RULES.URI)\n        break\n      end\n    end\n\n    if not hits.uri then\n      if plain_indexes.uris[req_uri] then\n        hits.uri     = req_uri\n        req_category = bor(req_category, MATCH_RULES.URI)\n\n      else\n        for i = 1, #prefix_uris do\n          if find(req_uri, prefix_uris[i].value, nil, true) == 1 then\n            hits.uri     = prefix_uris[i].value\n            req_category = bor(req_category, MATCH_RULES.URI)\n            break\n          end\n        end\n      end\n    end\n\n  end\n```\n如上所示，很明显当Kong收到一个请求后，首先遍历`regex_uris`看下当前请求能否被正则命中，如果不能则接着遍历`prefix_uris`，看下能否被前缀命中。\n\n由于那些流量很大的接口我们都使用了前缀路由，也就是说在这种情况下去命中一条路由我们需要遍历整个`regex_uris` ，正则匹配消耗了大量的CPU，符合火焰图观测结果。那么问题来了，我们能不能将之部分流量大的路由在匹配过程中前置，而不是每次都让`Kong`去遍历整个路由表？很显然是可以的。\n首先，我们可以将前缀路由转化为正则路由：\n\n```\n/foo -> /foo/(\\S+)\n```\n\n其次，为了让这个路由能够在`regex_uris`的尽可能靠前的位置我们可以设置`Regex priority`,给他一个足够大的值，这样Kong在生成内部路由表的时候对于正则路由会按照`Regex priority`排序\n\n\n按照上述思路对大流量的前缀路由进行调整，CPU过高的问题最终消失"},{"title":"如何使用GORM访问MySQL bit类型","url":"/2022/03/26/如何使用GORM访问MySQL bit类型/","content":"\n## 背景\n\n使用`GORM`访问`MySQL`，提示\n```\nC:/Development/Go/demohub/playground/gorm_test.go:111 sql: Scan error on column index 19, name \"Enabled\": converting driver.Value type []uint8 (\"\\x01\") to a int64: invalid syntax\n[1.626ms] [rows:1] SELECT * FROM `content` WHERE `id` = 546 LIMIT 1\n```\n这里`GORM`无法将`MySQL`的`bit(1)`转化为`Golang`的`bool`\n\n## 解决方法\n\n给bool类型定义一个alias，`BitBool`,并实现`Scan`及`Value`接口，如下所示：\n```golang\n// BitBool is an implementation of a bool for the MySQL type BIT(1).\n// This type allows you to avoid wasting an entire byte for MySQL's boolean type TINYINT.\ntype BitBool bool\n\n// Value implements the driver.Valuer interface,\n// and turns the BitBool into a bitfield (BIT(1)) for MySQL storage.\nfunc (b BitBool) Value() (driver.Value, error) {\n    if b {\n        return []byte{1}, nil\n    } else {\n        return []byte{0}, nil\n    }\n}\n\n// Scan implements the sql.Scanner interface,\n// and turns the bitfield incoming from MySQL into a BitBool\nfunc (b *BitBool) Scan(src interface{}) error {\n    v, ok := src.([]byte)\n    if !ok {\n        return errors.New(\"bad []byte type assertion\")\n    }\n    *b = v[0] == 1\n    return nil\n}\n```\n最后需要将`strut`中的bool字段替换为`BitBool`\n\n## 参考\n[MySQL's bit type maps to which Go type](https://stackoverflow.com/questions/47535543/mysqls-bit-type-maps-to-which-go-type)"},{"title":"使用IdentityModel.AspNetCore简化Token管理","url":"/2022/02/28/使用IdentityModel.AspNetCore简化Token管理/","content":"\n## 背景\n在日常开发过程中，我们常常需要通过`OAUTH2`去接入一些第三方站点，一般分为一下三个步骤:\n1. 通过`ClientId`,`ClientSecret`调用第三方的`TokenEndpoint`获取`AccessToken`\n2. 将步骤1得到的`AccessToken`进行缓存,避免重复获取`AccessToken`损耗应用性能\n3. 使用`AccessToken`调用第三方站点的`API`\n\n针对上面提到的3个步骤，我们通常会在应用中定义一个`TokenStore`来管理Token,当`HttpClient`发起调用的时候，我们会从`TokenStore`获取已缓存的`AccessToken`后设置`Authorization`头，如果涉及到`RefreshToken`的场景，那么整个过程会更加复杂，那么目前有没有一些基于`OAUTH2`标准的`Token`管理库呢? 答案是:`IdentityModel.AspNetCore`\n\n\n\n## IdentityModel.AspNetCore\n\n`IdentityModel.AspNetCore`是`IdentityServer4`开发团队开源的一个`Token`管理库,通过`IdentityModel.AspNetCore`我们无需关心`Token`的生命周期,`IdentityModel.AspNetCore`会根据`Token`的类型及生命周期自动为对应的`HttpClient`设置`Token`,使用方法如下所示:\n\n```\n/// <summary>\n///  添加外部服务clients\n/// </summary>\n/// <param name=\"services\"></param>\n/// <param name=\"appSettingConfig\"></param>\n/// <returns></returns>\npublic static IServiceCollection AddServiceClients(this IServiceCollection services, AppSettingConfig appSettingConfig)\n{\n    // 添加AddAccessTokenManagement\n    // 这里定一个与第三方idp通信的HttpClient\n    services.AddAccessTokenManagement(options =>\n    {\n        options.Client.Clients.Add(\"idp\", new ClientCredentialsTokenRequest()\n        {\n            Address = PathUtils.UrlCombine(appSettingConfig.HttpClientConfig.HttpClientMembers.FirstOrDefault(x => x.Name == \"idp\").BaseUrl, \"connect/token\"),\n            ClientId = appSettingConfig.JwtConfig.ClientId,\n            ClientSecret = appSettingConfig.JwtConfig.ClientSecret,\n        });\n    });\n\n    // AddClientAccessTokenHandler的本质是一个DelegateHandler\n    // 当HttpClient发起请求的时候会通过DelegateHandler自动设置Token\n    services.AddHttpClient<IThirdPartyClient, ThirdPartyClient>((sp, client) =>\n    {\n        client.Timeout = TimeSpan.FromSeconds(5);\n        client.BaseAddress = new Uri(appSettingConfig.HttpClientConfig.HttpClientMembers.FirstOrDefault(x => x.Name == \"third\").BaseUrl);\n    }).AddClientAccessTokenHandler(\"idp\");\n\n    return services;\n}\n\n```\n"},{"title":"EntityFramework Core 最佳实践","url":"/2022/01/10/EntityFramework Core最EntityFramework Core最佳实践/","content":"\n# 常见错误\n\n## 纯查询场景启用实体跟踪\n\n对于一些纯粹的查询接口，不涉及到修改，新增的业务场景，在使用Ef Core时，可以关闭实体跟踪功能，可以提升一定性能，eg：\n```\n var userList = dbContext.Users.AsNoTracking().ToListAsync();//当使用AsNoTracking()后，通过IQueryable得到的实体列表不会被DbContext跟踪到\n```\n\n\n## 重复跟踪实体对象\n\n对于那些不是通过`AsNoTracking()`得到的实体对象，Ef Core内部会自动通过`ChangeTracker`对这些实体对象进行跟踪，当需要将实体变更持久化到数据库时，不需要重复调用`Update`方法对实体对象进行跟踪。\n\n错误示范：\n\n```\nvar user = dbContext.Users.FirstOrDefault(x=>x.Id == 1);\nuser.Name = \"Loremipsum\";\ndbContext.Users.Update(user); // 这句话是不必要的\ndbContext.Users.SaveChanges();\n```\n\n\n正确示范:\n\n```\nvar user = dbContext.Users.FirstOrDefault(x=>x.Id == 1);\nuser.Name = \"Loremipsum\";\ndbContext.Users.SaveChanges();\n```\n\n\n## 避免查询断言中的常量表达式\n\nEf Core底层会将断言中的`lambda`表达式树进行编译并缓存，在开发，如果我们的查询中存在大量常量表达式，可能会导致内存泄漏\n\n错误示范:\n```\nvar user1 = dbContext.Users.FirstOrDefault(x=>x.Id == 1);\nvar user2 = dbContext.Users.FirstOrDefault(x=>x.Id == 2);\n```\n\n正确示范：\n```\nvar id = 1;\nvar user1 = dbContext.Users.FirstOrDefault(x=>x.Id == id);\nid = 2;\nvar user2 = dbContext.Users.FirstOrDefault(x=>x.Id == id);\n```\n\n\n# 一些常见性能优化的点\n\n## Dapper与Ef Core混用\n\n这是一种非常常见的实践，理由如下：\n\n1. Ef Core复杂查询自动生成的Sql性能不理想\n2. Ef Core需要一定配置才可以自动带出Dto，没有Dapper方便\n\n\n对于一些接入层的的复杂查询场景，用手写sql的方式可以获得更好的性能。\n\nDapper是`IDbConnection`的一个Extension库，例子如下：\n\n```\nstring sql = \"select * from users u  where u.Name like '%loremipsum%'\";\nvar userList = _dbContext.Database.GetDbConnection().QueryAsync<SomeDto>(sql);\n```\n\n\n## 使用Lazy Load而不是使用 Eager Load\n\n在Ef Core中Lazy Load默认是不开启的，需要进行如下配置：\n\n```\n services.AddDbContext<TestDbContext>(opt=>\n {\n    // 省略\n    opt.UseLazyLoadingProxies();\n }) \n```\n\n在项目文件中引入如下配置：\n```\n<PackageReference Include=\"Microsoft.EntityFrameworkCore.Proxies\" Version=\"5.0.10\" />\n```\n\n1. 减少代码量\n\nEager Load我们需要使用`Include`去获取导航属性，反之Lazy Load当我们访问导航属性的`Getter`时可以直接隐式获得这个导航属性\n\n2. Dto 投影\n\n当我们需要生成一个复杂的Dto的时候，我们不得不用使用`Include`，然后再将导航属性投影到Dto上面，假如我们的Dto只需要导航属性上面的2个Properties，我们仍然不得不查出导航属性上面所有的Properties\n\n使用Lazy Proxy与[AutoMapper QueryExtensions](https://docs.automapper.org/en/stable/Queryable-Extensions.html)可以减少投影过程中带来的损耗\n\n\n\n\n\n## 非必要场景，不要使用Code First\n\n1. 锁冲突：Code First生成的数据库模型会自动对关联关系生成外键，外键对数据库的性能造成一定影响，高并发场景下锁冲突的概率会大大增高\n2. 在多人合作开发场景下，Code First的Migrations不易管理\n\n\n\n# 技巧\n\n## CLR函数到MySQL函数的映射\n\n在使用Ef Core开发应用时，我们经常会发现我们的断言没办法正确的被翻译为Sql,很多时候是因为你的断言中包含了特定的函数，而这些函数不能被`Pomelo`所理解。\n\n`Pomelo`驱动对一些常见的CLR函数到MySQL函数的映射都进行了处理，那么当我们遇到一些Pomelo无法理解的CLR函数的时候，我们应该怎么样让他映射成一个MySQL函数呢：例子如下：\n\n```\n   /// <summary>\n    ///  使用前先确认函数已经通过HasDbFunction注册到DbContext,注意，单位是秒\n    /// </summary>\n    public static class MySqlDbFunctions\n    {\n        [DbFunction(\"STR_TO_DATE\")]\n        public static DateTime STR_TO_DATE(string dateStr, string format) => throw new NotSupportedException();\n        [DbFunction(\"CONCAT\")]\n        public static string CONCAT3(string str1,string str2,string str3) => throw new NotSupportedException();\n\n    }\n    protected override void OnModelCreating(ModelBuilder modelBuilder)\n        {\n            modelBuilder\n.HasDbFunction(() => MySqlDbFunctions.STR_TO_DATE(default(string), default(string)));\n            modelBuilder\n.HasDbFunction(() => MySqlDbFunctions.CONCAT3(default, default, default));\n        }\n```\n通过如上配置，可以将`STR_TO_DATA`，`CONCAT3`自动映射到MySql对应的库函数中\n"},{"title":"安装Kubernetes Dashboard","url":"/2021/11/13/安装Kubernetes Dashboard/","content":"\n\n## 获取安装文件\n\n首先打开[官方仓库](!https://github.com/kubernetes/dashboard),将dashboard.yml文件拷贝到k8s master主机上。由于dashboard无法支持外部直接访问，所以我们需要对yaml文件的配置内容进行少量修改:\n\n```\nkind: Service\napiVersion: v1\nmetadata:\n  labels:\n    k8s-app: kubernetes-dashboard\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nspec:\n  type: NodePort\n  ports:\n    - port: 443\n      targetPort: 8443\n      nodePort: 30001\n  selector:\n    k8s-app: kubernetes-dashboard\n\n```\n\n这里将`kubernetes-dashboard`的对应的`Service`修改为NodePort,让服务可以直接对外暴露。\n\n修改完毕后，执行部署\n```\nkubectl apply -f dashboard.yml\n```\n\n### 验证部署\n\n执行部署后，稍等片刻（拉去镜像需要耗费一定时间）后验证相关pod有没有在运行\n\n```console\n> kubectl -n kubernetes-dashboard get all\nNAME                                            READY   STATUS    RESTARTS   AGE\npod/dashboard-metrics-scraper-c45b7869d-9wclb   1/1     Running   0          51m\npod/kubernetes-dashboard-576cb95f94-v4lk2       1/1     Running   0          51m\n\nNAME                                TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE\nservice/dashboard-metrics-scraper   ClusterIP   10.104.124.208   <none>        8000/TCP        51m\nservice/kubernetes-dashboard        NodePort    10.99.67.103     <none>        443:30001/TCP   50m\n\nNAME                                        READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/dashboard-metrics-scraper   1/1     1            1           51m\ndeployment.apps/kubernetes-dashboard        1/1     1            1           51m\n\nNAME                                                  DESIRED   CURRENT   READY   AGE\nreplicaset.apps/dashboard-metrics-scraper-c45b7869d   1         1         1       51m\nreplicaset.apps/kubernetes-dashboard-576cb95f94       1         1         1       51m\n\n```\n\n\n\n### 配置权限\n\n```\napiVersion: v1\nkind: ServiceAccount              \nmetadata:\n  name: admin-user\n  namespace: kubernetes-dashboard\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: admin-user\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin                ## 将ServiceAccount授权，加入到 cluster-amdin组中，这个组具有对k8s超级管理员权限\nsubjects:\n- kind: ServiceAccount\n  name: admin-user\n  namespace: kubernetes-dashboard\n\n```\n获取用户token，用于登录：\n\n```\nkubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}')\n```\n\n\n### 登录验证\n\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/WeChat%20Screenshot_20211113144133.png)"},{"title":"使用BenchmarkDotNet测试Envoy中Grpc-Json协议转化的实际性能损耗","url":"/2021/11/08/使用BenchmarkDotNet测试Envoy中Grpc-Json协议转化的实际性能损耗/","content":"\n## 背景\n\nEnvoy目前作为最流行的的Service Mesh边车代理，提供了大量开箱即用的功能，极大的方便了开发人员。先前笔者就通过使用Envoy的Grpc-Json协议转化器，使得大量内部Grpc接口能够对Client端直接输出。那么Grpc-Json协议转化器会带来多少的性能损耗呢？相关项目上线后确实没有感觉出来，如果要找到确切的答案，还需要进行一定的测试才能给出\n\n\n## 实验方法\n\n为了测试`GrpcJsonTranscoder`接口的性能损耗，可以设计以下三个Grpc接口,这三个Grpc接口会通过Envoy进行协议转化\n\n```\nsyntax = \"proto3\";\n\noption csharp_namespace = \"GrpcJsonTranscondingPerfTest\";\nimport \"google/api/annotations.proto\";\n\npackage echo;\n\n\nservice EchoService {\n\n  rpc EchoWithSmallPayloadByGet (SmallPayloadRequest) returns (SmallPayloadResponse){\n    option (google.api.http) = {\n      get: \"/small\"\n    }; \n  }\n\n  rpc EchoWithSmallPayloadByPost (SmallPayloadRequest) returns (SmallPayloadResponse){\n    option (google.api.http) = {\n      post: \"/small\"\n      body: \"*\"\n    }; \n  }\n\n\n  rpc EchoWithMassivePayloadByPost (MassivePayloadRequest) returns (MassivePayloadResponse){\n    option (google.api.http) = {\n      post: \"/massive\"\n      body: \"*\"\n    }; \n  }\n}\n\n\nmessage SmallPayloadRequest {\n  string Message = 1;\n}\n\nmessage SmallPayloadResponse {\n  string Message = 1;\n}\n\n\nmessage MassivePayloadRequest {\n  repeated string StringList = 1;\n\trepeated int32 IntList= 2;\n}\n\nmessage MassivePayloadResponse {\n  repeated string StringList = 1;\n\trepeated int32 IntList= 2;\n}\n```\n\n此外，为了对比Envoy与原生ASP.NET CORE的性能损耗，还需三个原生的Restful接口:\n\n```\n    [ApiController]\n    public class Echo : ControllerBase\n    {\n        [HttpGet(\"small\")]\n        public Task<GrpcJsonTranscondingPerfTest.Common.Models.SmallPayloadResponse> EchoWithSmallPayloadByGet([FromQuery] GrpcJsonTranscondingPerfTest.Common.Models.SmallPayloadRequest request)\n        {\n           // ... 省略\n        }\n\n        [HttpPost(\"small\")]\n        public Task<GrpcJsonTranscondingPerfTest.Common.Models.SmallPayloadResponse> EchoWithSmallPayloadByPost([FromBody] GrpcJsonTranscondingPerfTest.Common.Models.SmallPayloadRequest request)\n        {\n           // ... 省略\n        }\n\n        [HttpPost(\"massive\")]\n        public Task<GrpcJsonTranscondingPerfTest.Common.Models.MassivePayloadResponse> EchoWithMassivePayloadByPost([FromBody] GrpcJsonTranscondingPerfTest.Common.Models.MassivePayloadRequest request)\n        {\n            // ... 省略\n        }\n```\n\n上述设计了验证以下3个问题:\n1. get请求与post请求\n2. 对于post请求，较小的payload与较大的payload会带来多少性能损耗\n3. 原生的ASP.NET Core相比较Envoy+Grpc谁拥有更好的性能?\n\n\n\n\n### 测试工具与环境\n\n\n#### Client环境\n\n工具: BenchmarkDotNet v0.13.1\n\nOS: Windows 10.0.19043.1288 (21H1/May2021Update)\n\nCPU: Intel Core i7-8750H CPU 2.20GHz (Coffee Lake), 1 CPU, 12 logical and 6 physical cores\n\n.NET SDK: 5.0.104\n\n#### Server环境\n\n边车代理: Envoy v1.19.1\n\nOS: ubuntu 20.04\n\nCPU: Intel Core i7-4710MQ CPU 2.50GHz (Haswell), 1 CPU, 8 logical and 4 physical cores\n\n.NET SDK: 5.0.502\n\n\n\n## 测试结果\n由于这个测试输出较长，这里仅仅截取结论部分，如果对相关细节感兴趣，可以参考[测试源码](https://github.com/LoremipsumSharp/GrpcJsonTranscondingPerfTest)\n\nASP.NET Core原生调用\n\n|                   Method |     Mean |     Error |    StdDev |\n|------------------------- |---------:|----------:|----------:|\n|    SendSmallPayloadByGet | 5.954 ms | 0.1158 ms | 0.3011 ms |\n|   SendSmallPayloadByPost | 6.274 ms | 0.1614 ms | 0.4604 ms |\n| SendMassivePayloadByPost | 6.952 ms | 0.2388 ms | 0.7004 ms |\n\nGrpc原生调用\n\n\n|                   Method |     Mean |     Error |    StdDev | \n|------------------------- |---------:|----------:|----------:|\n|    SendSmallPayloadByGet | 6.274 ms | 0.3606 ms | 1.0228 ms | \n|   SendSmallPayloadByPost | 6.350 ms | 0.3220 ms | 0.8704 ms |\n| SendMassivePayloadByPost | 5.520 ms | 0.1093 ms | 0.1258 ms |\n\nGrpc+Envoy调用\n\n|                   Method |     Mean |     Error |    StdDev |\n|------------------------- |---------:|----------:|----------:|\n|    SendSmallPayloadByGet | 6.989 ms | 0.1394 ms | 0.3367 ms |\n|   SendSmallPayloadByPost | 7.489 ms | 0.1518 ms | 0.4207 ms |\n| SendMassivePayloadByPost | 7.874 ms | 0.1988 ms | 0.5800 ms |\n\n\n\n## 结论\n\n从测试接口可以看出，当使用Envoy对Grpc接口进行协议转换的时候，随着payload越大，整个耗时越长，但是实际的整个性能损耗对于大部分业务场景来讲，都是可以接受的\n\n"},{"title":"使用Diagnostics Client实时获取.NetCore应用的性能指标","url":"/2021/11/06/使用Diagnostics Client实时获取.Net Core应用的性能指标/","content":"\n## 背景\n\n.NET Core 3.0引入了一个新的Cli工具`dotnet-counters`,通过`dotnet-counters`，我们可以很轻松的获取.NET Runtime的相关性能指标，如下所示：\n\n```console\n> dotnet-counters list\nShowing well-known counters only. Specific processes may support additional counters.\n\nSystem.Runtime\n    cpu-usage                                    Amount of time the process has utilized the CPU (ms)\n    working-set                                  Amount of working set used by the process (MB)\n    gc-heap-size                                 Total heap size reported by the GC (MB)\n    gen-0-gc-count                               Number of Gen 0 GCs per interval\n    gen-1-gc-count                               Number of Gen 1 GCs per interval\n    gen-2-gc-count                               Number of Gen 2 GCs per interval\n    time-in-gc                                   % time in GC since the last GC\n    gen-0-size                                   Gen 0 Heap Size\n    gen-1-size                                   Gen 1 Heap Size\n    gen-2-size                                   Gen 2 Heap Size\n    loh-size                                     LOH Heap Size\n    alloc-rate                                   Allocation Rate\n    assembly-count                               Number of Assemblies Loaded\n    exception-count                              Number of Exceptions per interval\n    threadpool-thread-count                      Number of ThreadPool Threads\n    monitor-lock-contention-count                Monitor Lock Contention Count\n    threadpool-queue-length                      ThreadPool Work Items Queue Length\n    threadpool-completed-items-count             ThreadPool Completed Work Items Count\n    active-timer-count                           Active Timers Count\n\nMicrosoft.AspNetCore.Hosting\n    requests-per-second                  Request rate\n    total-requests                       Total number of requests\n    current-requests                     Current number of requests\n    failed-requests                      Failed number of requests\n```\n\n这些性能指标极大的方便了线上应用的故障诊断，但是在很多情况下，开发人员及运维人员是无法24h去盯着这些指标，往往是在监控告警后才会开始进行问题的排查，在这种背景下，会出现以下两个需求：\n1. 通过性能指标进行告警\n2. 对性能指标这一类时序数据进行存储，用于后续分析\n\n\n很显然为了满足上述的两个需求，仅仅通过`dotnet-counters`是很难实现的，是否存在一种可编程的方法来获取上述的性能指标？答案是就是`Microsoft.Diagnostics.NETCore.Client`\n\n\n\n## Microsoft.Diagnostics.NETCore.Client\n\n实际上，如果查阅`dotnet-counters`，`dotnet-gcdump `的源码就可以发现，这些cli诊断工具的底层实际上是基于`Microsoft.Diagnostics.NETCore.Client`，那么很显然，我们可以通过引用Nuget包的形式`Microsoft.Diagnostics.NETCore.Client`，通过调用相关API来实现对.NET Core进程的性能指标收集。\n\n如下所示，下述代码，笔者将这一系列指标通过WebSocket传递到前端：\n\n```\n  [HttpGet(\"/counter\")]\n        public async Task PerformanceCounter([FromQuery] string counterName, [FromQuery] string service = \"nhost\", [FromQuery] string interval = \"10 \")\n        {\n            // 是否是websocket连接?\n            if (!HttpContext.WebSockets.IsWebSocketRequest)\n                throw new NotSupportedException(\"ws is required for getting performance counter\");\n\n            \n            var websocket = await HttpContext.WebSockets.AcceptWebSocketAsync();\n\n            // 获取System.Runtime相关counter,每10秒获取一些\n            var providers = new List<EventPipeProvider>()\n            {\n              new EventPipeProvider(\"System.Runtime\",\n              EventLevel.Informational, arguments: new Dictionary<string, string>\n              {\n                {\"EventCounterIntervalSec\", interval}\n              })\n            };\n\n            var client = new DiagnosticsClient(Process.GetCurrentProcess().Id);\n            var session = client.StartEventPipeSession(providers, false);\n            var source = new EventPipeEventSource(session.EventStream);\n            var output = new Subject<string>();\n            source.Dynamic.All += obj =>\n            {\n                if (obj.EventName == \"EventCounters\")\n                {\n                    var payload = (IDictionary<string, object>)obj.PayloadValue(0);\n\n                    if (!string.IsNullOrWhiteSpace(counterName))\n                        payload = payload.Where(x => x.Value.ToString().TryParse(out var jObj) &&\n                        string.Equals(counterName, jObj[\"Name\"]?.ToString()))\n                        .ToDictionary(x => x.Key, x => x.Value);\n                    foreach (var item in payload)\n                    {\n                        output.OnNext(item.Value.ToString());\n                    }\n                }\n            };\n\n            this.HttpContext.RequestAborted.Register(() => session.Dispose());\n            var task = Task.Factory.StartNew(\n                            () => source.Process(),\n                            HttpContext.RequestAborted,\n                            TaskCreationOptions.LongRunning, TaskScheduler.Default);\n\n            await Echo(websocket, output);\n\n        }\n```\n\n## 结语\n\n笔者先前在做相关的应用性能监控平台遇到了这个问题，最开始笔者是打算直接使用一个进程将cli工具`dotnet-counters`启动起来，并对其标准输出流进行截取，后来发现这样做实在太麻烦了，光字符串处理就要做一大堆判断。后来通过查阅官方的源码，发现使用`Microsoft.Diagnostics.NETCore.Client`才是标准做法，并进行了尝试及验证，发现这个方案是可行的。"},{"title":"通过Reactive.NET来理解Async&Await","url":"/2021/08/16/通过Reactive.NET来理解Async&Await/","content":"\n## 前置知识\n\n如果一个.NET应用通过async/await执行一个异步方法时，一旦遇到一些特定的I/O操作，\n\n如磁盘I/O:\n```\nFile.ReadAllTextAsync\n```\n网络I/O:\n```\nHttpClient.GetStringAsync\n```\n这个时候工作线程会被释放掉，取而代之的是I/O线程，I/O线程会去监听操作系统的相关I/O事件(Windows:IOCP,  *niux:epoll)，直到相关I/O事件产生后，将具体的I/O结果返回给应用。当发生具体的I/O操作的时工作线程实际上不会被挂起，可以继续工作(这也是async/await的一个好处之一，减少cpu上下文切换)\n\n\n## 实例演示\n\n为了证明猜测的正确性，这里我们使用Reactive.NET中自带的EventLoopScheduler,通过EventLoopScheduler,我们可以保证await之前代码使用执行在一条工作线程之上\n\n```\npublic void Test2()\n{\n    EventLoopScheduler eventLoopScheduler = new EventLoopScheduler();\n\n    System.Text.Encoding.RegisterProvider(System.Text.CodePagesEncodingProvider.Instance);\n    var disposeable1 = Observable.Create<string>(async observer =>\n    {\n        var client = new HttpClient();\n        _testOutputHelper.WriteLine($\"observable1 started: {Thread.CurrentThread.ManagedThreadId}\");\n        var result = await client.GetStringAsync(\"https://www.baidu.com\");\n        observer.OnNext(result);\n        observer.OnCompleted();\n        _testOutputHelper.WriteLine($\"observable1 completed: {Thread.CurrentThread.ManagedThreadId}\");\n        return Disposable.Create(() =>\n        {\n            client.Dispose();\n        });\n    }).ObserveOn(eventLoopScheduler).SubscribeOn(eventLoopScheduler)\n    .Subscribe(item =>\n    {\n        _testOutputHelper.WriteLine(\"observable1 consumed\");\n    });\n\n    var disposeable2 = Observable.Create<string>(async observer =>\n   {\n       var client = new HttpClient();\n       _testOutputHelper.WriteLine($\"observable2 started: {Thread.CurrentThread.ManagedThreadId}\");\n       var result = await client.GetStringAsync(\"https://www.sina.com.cn\");\n       observer.OnNext(result);\n       observer.OnCompleted();\n       _testOutputHelper.WriteLine($\"observable2 completed : {Thread.CurrentThread.ManagedThreadId}\");\n       return Disposable.Create(() =>\n       {\n           client.Dispose();\n       });\n   }).ObserveOn(eventLoopScheduler).SubscribeOn(eventLoopScheduler)\n   .Subscribe(item =>\n   {\n       _testOutputHelper.WriteLine(\"observable2 consumed\");\n   });\n\n    Thread.Sleep(1000 * 30);\n}\n```\n\n输出内容:\n\n```\nobservable1 started: 25\nobservable2 started: 25\nobservable1 completed: 7\nobservable1 consumed\nobservable2 completed : 7\nobservable2 consumed\n```\n\n\n可以看出当observable1被I/O阻塞掉之后，工作线程会继续执行observable2的相关代码，都是同一个线程ID。\n你可能会好奇为什么completed的时候线程ID是7，那是因为await之后的线程是取决于当前同步上下文，可以参考我另外一篇文章：\n[Await&Await是如何导致死锁的](https://loremipsumsharp.github.io/2021/04/03/Await&Await%E6%98%AF%E5%A6%82%E4%BD%95%E5%AF%BC%E8%87%B4%E6%AD%BB%E9%94%81%E7%9A%84/)"},{"title":"使用Autofixture提高单元测试编写效率","url":"/2021/06/13/使用Autofixture提高单元测试编写效率/","content":"\n## 背景\n\n在编写单元测试的过程中，我们常常需要将一些测试的非关注点以Moq的形式去掉，如一些外部的grpc调用、数据库依赖，redis依赖等。eg:\n\n```\n[Fact]\npublic async Task TestAddSubscription_WhenExists_ThrownException()\n{\n    // arrange\n    var subscription = new Subscription()\n    {\n        SourceCode = \"sys_db-pt_role\",\n        SourceVersion = 2,\n        SourceTimestamp = 1622014384,\n        TargetCode = \"EU-Target/EU-SYS-Db/sys_db-pt_role\",\n        TargetVersion = 0,\n        TargetTimestamp = 0,\n        Status = SubscriptionStatus.UnSynchronized,\n        LastPullTime = DateTime.Now,\n        CreateTime = DateTime.Now,\n        IsEnable = true\n    };\n    var mockSubscriptionRepo = new Mock<ISubscriptionRepository>();\n    mockSubscriptionRepo.Setup(x => x.GetSubscription(subscription.SourceCode, subscription.TargetCode))\n    .ReturnsAsync(new Subscription());\n    var mockTargetServerRepository = new Mock<ITargetServerRepository>();\n    var mockTargetServerClient = new Mock<ITargetServerClient>();\n    var mockPushTaskRepository = new Mock<IPushTaskRepository>();\n    var mockSourceServerClient = new Mock<ISourceServerClient>();\n    SubscriptionService subscriptionService = new SubscriptionService(mockTargetServerRepository.Object,mockSubscriptionRepo.Object,targetServerClient.Object,mockPushTaskRepository.Object,mockSourceServerClient.Object)\n\n    // act\n    Task act() => subscriptionService.AddSubscription(subscription, new TargetServer(), string.Empty, string.Empty, string.Empty);\n\n    // assert\n    await Assert.ThrowsAsync<SiteErrorException>(act);\n\n}\n```\nSubscriptionService的定义如下:\n\n```\n\n public class SubscriptionService : ISubscriptionService\n {\n    private readonly ITargetServerRepository _targetServerRepository;\n    private readonly ISubscriptionRepository _subscriptionRepository;\n    private readonly IPushTaskRepository _pushTaskRepository;\n    private readonly ITargetServerClient _targetServerClient;\n    private readonly ISourceServerClient _sourceServerClient;\n    private readonly ILogger<SubscriptionService> _logger;\n\n    private static string _lockKeyPattern = \"{0}:{1}:SubscriptionSync\";\n    private static readonly ConcurrentDictionary<string, SemaphoreSlim> _locks = new ConcurrentDictionary<string, SemaphoreSlim>();\n\n    public SubscriptionService(ITargetServerRepository targetServerRepository, ISubscriptionRepository subscriptionRepository, ITargetServerClient targetServerClient, IPushTaskRepository pushTaskRepository, ISourceServerClient sourceServerClient, ILogger<SubscriptionService> logger)\n    {\n        _targetServerRepository = targetServerRepository;\n        _subscriptionRepository = subscriptionRepository;\n        _targetServerClient = targetServerClient;\n        _pushTaskRepository = pushTaskRepository;\n        _sourceServerClient = sourceServerClient;\n        _logger = logger;\n    }\n }\n```\n\n上述写法存在的弊端：\n\n1. 需要Mock大量对象，导致单元测试的arrange阶段极为冗长\n2. 如果SubscriptionServices的构造函数发生变化，那么这个单元测试无法通过\n\n实际上，在上面的这个单元测试，我们仅仅关注ISubscriptionRepository，那么有没有办法通过一些手段来解决问题1、2呢？\n\n## 使用Autofixture编写单元测试\n\nAutoFixture 是一个 .NET 的开源框架，主要设计目的是最小化单元测试的arrange阶段。可以让开发者把重点放在测试的目标而不是设置测试场景。\n\n通过Autofixture,可以实现Moq的自动化，我们只需要将我们的精力聚焦在我们要测试的点上，也就是说我们只需要关注我们测试需要用到的一些Mock对象。\n\n通过Autofixture重构后的代码如下所示：\n\n```\npublic class TestSubscriptionService\n{\n    private readonly Fixture _fixture;\n    public TestSubscriptionService()\n    {\n        _fixture = new Fixture();\n        _fixture.Customize(new AutoMoqCustomization());\n    }\n    [Fact]\n    public async Task TestAddSubscription_WhenExists_ThrownException()\n    {\n        var subscription = new Subscription()\n        {\n            SourceCode = \"sys_db-pt_role\",\n            SourceVersion = 2,\n            SourceTimestamp = 1622014384,\n            TargetCode = \"EU-Target/EU-SYS-Db/sys_db-pt_role\",\n            TargetVersion = 0,\n            TargetTimestamp = 0,\n            Status = SubscriptionStatus.UnSynchronized,\n            LastPullTime = DateTime.Now,\n            CreateTime = DateTime.Now,\n            IsEnable = true\n        };\n        var mockSubscriptionRepo = new Mock<ISubscriptionRepository>();\n        mockSubscriptionRepo.Setup(x => x.GetSubscription(subscription.SourceCode, subscription.TargetCode))\n            .ReturnsAsync(new Subscription());\n        _fixture.Register<ISubscriptionRepository>(() => mockSubscriptionRepo.Object);\n        SubscriptionService subscriptionService = _fixture.Create<SubscriptionService>();\n\n        Task act() => subscriptionService.AddSubscription(subscription, new TargetServer(), string.Empty, string.Empty, string.Empty);\n\n        await Assert.ThrowsAsync<SiteErrorException>(act);\n\n    }\n}\n```\n\n如上所示:\n1. 当构造函数发生变更后，我们无需重写单元测试，Autofixture会自动帮我们Mock一些非测试关注的对象\n2. 极大的简化了arrange阶段的代码量\n\n## 参考\n[How to add a specific implementation of a Mock created with Autofixture](https://stackoverflow.com/questions/34788365/how-to-add-a-specific-implementation-of-a-mock-created-with-autofixture)\n\n[Constructor strategies for AutoFixture](https://blog.ploeh.dk/2011/04/19/ConstructorstrategiesforAutoFixture/)"},{"title":"使用SourceLink调试Nuget包源码","url":"/2021/05/16/使用SourceLink调试Nuget包/","content":"\n\n## 背景\n\n在日常开发中，我们将一些封装好的类库以nuget包的形式发布到nuget服务器上，通过引用这些nuget包来增加开发效率，减少重复代码。由于nuget包的本质上是一个dll，在使用nuget包的过程中，我们无法直接调试与之对应的源码，当一些以nuget包提供的第三方类库报错或发生异常时，我们往往需要去相应的仓库克隆相关的源码，并将nuget包引用替换为源码引用，通过直接源码调试来定位具体的问题。\n\n那么是否存在一种开箱即用的工具，能够应付上述的场景?答案是:[SourceLink](https://github.com/dotnet/sourcelink)\n\nSourceLink是Microsoft的一个开源项目，开发者只需在项目文件(.csproj)进行简单的配置便可以让生成的nuget包嵌入相关的源码信息。当开发者进行调试的时候，.NET Debugger便会利用pdb文件中的源码信息，直接将断点定位具体源码，用户无需再去克隆相关源码进行调试。\n\n目前SourceLink支持的最低.NET CORE SDK版本是2.1.300\n\n\n## 项目设置\n\n\n在项目文件增加如下的配置项：\n\n```\n<PropertyGroup>\n    <PublishRepositoryUrl>true</PublishRepositoryUrl>\n    <EmbedUntrackedSources>true</EmbedUntrackedSources>\n    <IncludeSymbols>true</IncludeSymbols>\n    <SymbolPackageFormat>snupkg</SymbolPackageFormat>\n    <!-- <EmbedAllSources>true</EmbedAllSources> -->\n  </PropertyGroup>\n```\n\n### IncludeSymbols && SymbolPackageFormat\n\n这两个设置可以让发布nuget包带上pdb信息\n\n### EmbedUntrackedSources && EmbedAllSources\n\n当EmbedAllSources设置为true的时候，会将所有源码信息内嵌到pdb文件中，后续调试的时候不需要再从git拉取。反之EmbedUntrackedSources则只会将那些没有被git管理到源码嵌入到pdb文件中\n\n### PublishRepositoryUrl\n\n让sourcelink可以找到相关的源码文件\n\n## 源码控制设置\n目前sourcelink支持一下集中源码管理：\n\n\n```\nMicrosoft.SourceLink.GitHub (depends on Microsoft.Build.Tasks.Git package)\nMicrosoft.SourceLink.AzureRepos.Git (depends on Microsoft.Build.Tasks.Git package)\nMicrosoft.SourceLink.AzureDevOpsServer.Git (depends on Microsoft.Build.Tasks.Git package)\nMicrosoft.SourceLink.GitLab (depends on Microsoft.Build.Tasks.Git package)\nMicrosoft.SourceLink.Bitbucket.Git (depends on Microsoft.Build.Tasks.Git package)\n```\n\n如过你的nuget包的源码是托管再github上，那么再项目文件中需要增加如下引用\n\n\n```\n<ItemGroup Label=\"SourceLink\">\n    <PackageReference Include=\"Microsoft.SourceLink.GitHub\" Version=\"1.0.0\" PrivateAssets=\"All\" >\n      <PrivateAssets>all</PrivateAssets>\n      <IncludeAssets>runtime; build; native; contentfiles; analyzers</IncludeAssets>\n    </PackageReference>\n  </ItemGroup>\n```\n###  构建并打包\n\n\n```\ndotnet build -c Release\ndotnet pack -c Release\n```\n安装sourcelink cli工具\n\n\n```\ndotnet tool install --global sourcelink\n```\n\n验证相关的pdb文件\n\n\n```\n$ sourcelink test SVNSourceLinkDemo.Common.pdb \nsourcelink test passed: SVNSourceLinkDemo.Common.pdb\n```\n\n查看相关sourcelink信息\n\n\n```\n$ sourcelink print-json  SVNSourceLinkDemo.Common.pdb\n{\"documents\":{\"C:\\\\Development\\\\NetCore\\\\SVNSourceLinkDemo\\\\*\":\"https://raw.githubusercontent.com/LoremipsumSharp/SVNSourceLinkDemo/8a302ea20ba8b3d3fd81086f2f28a0c7183e185a/*\"}}\n```\n\n\n其中注意到**8a302ea20ba8b3d3fd81086f2f28a0c7183e185a**，这个guid是git的commit id\n\n\n## 调试配置\n\n\n\n```\n{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            // Use IntelliSense to find out which attributes exist for C# debugging\n            // Use hover for the description of the existing attributes\n            // For further information visit https://github.com/OmniSharp/omnisharp-vscode/blob/master/debugger-launchjson.md\n            \"name\": \".NET Core Launch (console)\",\n            \"type\": \"coreclr\",\n            \"request\": \"launch\",\n            \"preLaunchTask\": \"build\",\n            // If you have changed target frameworks, make sure to update the program path.\n            \"program\": \"${workspaceFolder}/bin/Debug/netcoreapp2.1/HelloWorld.dll\",\n            \"args\": [],\n            \"cwd\": \"${workspaceFolder}\",\n            // For more information about the 'console' field, see https://aka.ms/VSCode-CS-LaunchJson-Console\n            \"console\": \"internalConsole\",\n            \"stopAtEntry\": false,\n            \"justMyCode\": false,\n            \"symbolOptions\": {\n                \"searchPaths\": [],\n                \"searchMicrosoftSymbolServer\": true,\n                \"searchNuGetOrgSymbolServer\": true,\n                \"moduleFilter\": {\n                    \"mode\": \"loadOnlyIncluded\",\n                    \"excludedModules\": [\"SVNSourceLinkDemo*.dll\"]\n                }\n            }\n        },\n        {\n            \"name\": \".NET Core Attach\",\n            \"type\": \"coreclr\",\n            \"request\": \"attach\",\n            \"processId\": \"${command:pickProcess}\"\n        }\n    ]\n}\n```\n其中justMyCode与symbolOptions是新增vscode调试配置\n\n\n\n\n## 参考\n[SEAMLESS DEBUGGING OF NUGET PACKAGES](https://queil.net/blog/2019/seamless-debugging-of-nuget-packages/)\n"},{"title":"使用Utf8Json改善Ocelot对象序列化的性能","url":"/2021/04/07/使用Utf8Json改善Ocelot对象序列化的性能/","content":"\n## 背景\n\n近期在对部门的crm系统进行服务化改造，服务化改造过程中，选择了ocelot作为api网关。各个服务的response到达ocelot之后，ocelot会对response做进一步封装，形成统一的规范格式后再返回给client，eg：\n\n\n```\n\n    public class Response\n    {\n        public Response(object data)\n        {\n            Code = 0;\n            Data = data;\n            Message = \"Success\";\n        }\n        public Response(string message, int code = 500)\n        {\n            Code = code;\n            Message = message;\n        }\n        public int Code { get; set; }\n\n        public string Message { get; set; }\n\n        public object Data { get; set; } // 服务端返回的数据\n\n        public bool Success { get { return Code == 0; } }\n\n        public string Error {get;set;}\n```\n\n通过ocelot对response格式进行统一处理，这样依赖就不需要每个服务再去单独写一个ResultFilter来处理，减少了大量重复代码。\n\n为了实现这个功能，那么就必须在ocelot中对各个服务的response进行序列化/反序列化处理。这样势必对ocelot的性能造成一定的影响。\n那么有没有办法优化序列化/反序列化的性能呢？\n\n\n## Utf8Json\n\n[Utf8Json](https://github.com/neuecc/Utf8Json) 是一个日本人写的一个Json序列化器，目前宣称是拥有最好的序列化性能。相关[结论](https://michaelscodingspot.com/the-battle-of-c-to-json-serializers-in-net-core-3/)也支持这一观点:\n\n**For serialization, Utf8Json is 2 times faster than System.Text.Json and a whole 4 times faster than Newtonsoft. For deserialization, Utf8Json is 3.5 times faster than System.Text.Json and 6 times faster than Newtonsoft.**\n\n\n查阅官方文档，utf8json之所以这么快主要原因有如下几个：\n\n1. 不需要额外的内存分配\n以Json.NET为例，如果我们希望将一个对象变成一个字节数组,待会会有以下两种方法：\n\n方法一：\n```\npublic static byte[] SerializeJson(DrawDescriptionLayer layer)\n{\n    var s = JsonConvert.SerializeObject(layer, js);\n    return Encoding.UTF8.GetBytes(s); //rent from array pool here\n}\n```\n\n\n方法二：\n\n```\npublic static byte[] SerializeJson2(DrawDescriptionLayer layer)\n{\n    using (var ms = new MemoryStream())\n    using (StreamWriter writer = new StreamWriter(ms, Encoding.UTF8))\n    using (JsonTextWriter jsonWriter = new JsonTextWriter(writer))\n    {\n        JsonSerializer ser = JsonSerializer.Create(js);\n        ser.Serialize(jsonWriter, layer);\n        jsonWriter.Flush();\n        return ms.ToArray(); //rent from array pool here\n    }\n}\n```\n\n以上两种方法都无一例外的产生了额外的内存分配，效率不高。以方法二为例，创建一个新的streamwriter就会导致一个bytes[3075]的allocation，很有可能我们并不需要这么多，同理UTF8.GetBytes也有这个问题。\n\n而Utf8json则做到了按需分配，比如，当我们执行如下代码：\n\n```\nvar bytes = Utf8Json.JsonSerializer.Serialize(obj1, jsonresolver);\n```\n\nutf8json首先会从内存池取出一个buffer（每个线程一个副本）来生成bytes数组的具体内容\n\n\n```\npublic static byte[] Serialize<T>(T value, IJsonFormatterResolver resolver)\n        {\n            if (resolver == null) resolver = DefaultResolver;\n\n            var writer = new JsonWriter(MemoryPool.GetBuffer());\n            var formatter = resolver.GetFormatterWithVerify<T>();\n            formatter.Serialize(ref writer, value, resolver);\n            return writer.ToUtf8ByteArray();\n        }\n```\n然后将bytes数据拷贝的dst后返回给调用端\n\n```\nbyte[] FastCloneWithResize(byte[] src, int newSize)\n        {\n            if (newSize < 0) throw new ArgumentOutOfRangeException(\"newSize\");\n            if (src.Length < newSize) throw new ArgumentException(\"length < newSize\");\n\n            if (src == null) return new byte[newSize];\n\n            byte[] dst = new byte[newSize];\n\n#if NETSTANDARD && !NET45\n            fixed (byte* pSrc = &src[0])\n            fixed (byte* pDst = &dst[0])\n            {\n                Buffer.MemoryCopy(pSrc, pDst, dst.Length, newSize);\n            }\n#else\n            Buffer.BlockCopy(src, 0, dst, 0, newSize);\n#endif\n\n            return dst;\n        }\n```\n这样依赖内存可以复用，并且没有带来额外的损耗\n\n2.对数值型到字符串的转化进行了特定的优化，如int->string（itoa）,double->string(google/double-conversion)\n\n\n3.[优化了Buffer.MemoryCopy的性能问题](https://github.com/dotnet/coreclr/pull/3118)\n\n\n等等。\n\n\n\n## 重构\n\n定义一个Formatter专门用于处理服务端的response：\n\n\n```\n/// <summary>\n    ///  Utf8Json的JRaw,压榨性能\n    /// </summary>\n    public class JRawFormatter : IJsonFormatter<JRaw>\n    {\n        public static JRawFormatter Instance;\n\n        static JRawFormatter()\n        {\n            Instance = new JRawFormatter();\n        }\n\n\n        /// <summary>\n        ///  没有反序列化场景，暂时不管\n        /// </summary>\n        /// <param name=\"reader\"></param>\n        /// <param name=\"formatterResolver\"></param>\n        /// <returns></returns>\n        public JRaw Deserialize(ref JsonReader reader, IJsonFormatterResolver formatterResolver)\n        {\n            throw new System.NotImplementedException();\n        }\n\n        /// <summary>\n        ///  \n        /// </summary>\n        /// <param name=\"writer\"></param>\n        /// <param name=\"value\"></param>\n        /// <param name=\"formatterResolver\"></param>\n        public void Serialize(ref JsonWriter writer, JRaw value, IJsonFormatterResolver formatterResolver)\n        {\n            if (value == null)\n            {\n                writer.WriteNull();\n                return;\n            }\n\n            writer.WriteRaw(value.Payload);\n\n        }\n    }\n```\n处理服务端返回：\n\n\n```\npublic override async Task SetResponseOnHttpContextBody(HttpContext httpContext, DownstreamResponse response)\n        {\n            object body = default;\n\n            if (response.IsEmptyResponse())\n            {\n                body = new Response(null, 0);\n                httpContext.Response.StatusCode = (int)HttpStatusCode.OK;\n            }\n            else\n            {\n                var responsePayload = await response.Content.ReadAsStringAsync();\n                body = new Response(new JRaw(responsePayload));\n            }\n\n\n            var bodyBytes = Encoding.UTF8.GetBytes(JsonConvert.SerializeObject(body, _settings));\n            httpContext.Response.Headers.AddOrReplaceHeaderKey(\"Content-Length\", bodyBytes.Length.ToString());\n            await httpContext.Response.Body.WriteAsync(bodyBytes);\n        }\n```\n\n\n## 参考\n\n\n[Utf8Json](https://github.com/neuecc/Utf8Json)\n\n[The Battle of C# to JSON Serializers in .NET Core 3](https://michaelscodingspot.com/the-battle-of-c-to-json-serializers-in-net-core-3/)\n\n[Re-use memory from String to byte array conversion with ArrayPool in C#?](https://stackoverflow.com/questions/56379096/re-use-memory-from-string-to-byte-array-conversion-with-arraypool-in-c)"},{"title":"Async/Await是如何导致死锁的","url":"/2021/04/03/Await&Await是如何导致死锁的/","content":"\n## 背景\n在使用Async/Await的过程中，经常出现原因不明的死锁，感觉代码写的没啥问题，但是程序就是卡住了，为了明白这个问题，必须知道async/await的相关原理\n\n\n## 当程序遇到await关键字后会怎么处理\n\n当程序遇到await的关键字后，会做以下事件：\n\n1. 将await关键字后面的相关操作注册为一个回调\n2. 释放当前线程T\n3. 如果SynchronizationContext.Current不为null，那么在步骤1的回调将通过SynchronizationContext.Post去执行（最终是步骤2的线程T去执行这段代码）\n4. 如果SynchronizationContext.Current为null，那么在步骤1的回调将会通过线程池里面的线程去执行\n\n\n\n### 为什么会产生死锁\n如下图所示：\n[![cZt6sJ.png](https://z3.ax1x.com/2021/04/02/cZt6sJ.png)](https://imgtu.com/i/cZt6sJ)\n\n1. 在UI线程我们调用了Wait()或者.Result，这个时候UI线程会等待异步结果\n2. I/O线程异步操作结束后，根据以上描述，I/O线程需要SynchronizationContext.Post来继续执行await后面的逻辑，谁来执行？必然是UI线程，但是UI线程仍然在等待异步的结果，这个时候I/O线程和UI线程会出现相互等待导致死锁产生\n\n\n\n### 如何避免死锁\n\n如下图所示：\n\n[![cmL6oD.md.png](https://z3.ax1x.com/2021/04/03/cmL6oD.md.png)](https://imgtu.com/i/cmL6oD)\n\n使用``ConfigureAwait ``,使用ConfigureAwait，回调会通过线程池中的线程去执行，而不是SynchronizationContext关联线程(UI线程)，所以解决了这个主要矛盾，就没有死锁了\n\n\n\n### 结论\n\n由于async/await的底层使用了SynchronizationContext，SynchronizationContext有多种实现（console，gui，web）。在.NET FRAMEWORK环境下进行了实验，不仅在winform，在MVC中，在异步方法中进行同步调用，也会产生死锁。\n但是在.NET CORE中，由于取消了SynchronizationContext，在异步方法中直接进行同步调用是没有问题的，可以放心调用，但是还是不建议这样做\n\n\n\n### 参考\n[The danger of async/await and .Result in one picture](https://tooslowexception.com/the-danger-of-asyncawait-and-result-in-one-picture/)"},{"title":"使用dotnet template engine创建项目模板","url":"/2021/03/01/使用dotnet template engine创建项目模板/","content":"\n\n\n## 背景\ndotnet sdk安装后默认配套了若干开发模板，使用dotnet new 命令可以让开发者快速通过开发模板搭建项目。这些内置的开发模板基本可以满足日常的开发需求，但是对于一些特定场景，比如开发者想在Abp的基础上快速搭建项目，那么必须利用 [dotnet template engine](https://github.com/dotnet/templating)    来进行模板的定制化开发\n\n\n其实在dotnet core出来之前，比较流行的的代码自动生成的方式是利用Visual Studio内置的 [T4模板引擎](https://docs.microsoft.com/en-us/visualstudio/modeling/code-generation-and-t4-text-templates?view=vs-2019)  如下：\n\n\n\n```\n<#@ template debug=\"true\" hostSpecific=\"true\" #>\n<#@ output extension=\".cs\" #>\n<#@ Assembly Name=\"System.Core\" #>\n<#@ Assembly Name=\"System.Windows.Forms\" #>\n<#@ assembly name=\"EnvDTE\" #>  \n<#@ import namespace=\"EnvDTE\" #>  \n<#@ import namespace=\"System\" #>\n<#@ import namespace=\"System.IO\" #>\n<#@ import namespace=\"System.Diagnostics\" #>\n<#@ import namespace=\"System.Linq\" #>\n<#@ import namespace=\"System.Collections\" #>\n<#@ import namespace=\"System.Collections.Generic\" #> \n<#//修改using #>\nusing AAM.ProductManagement.Core.Models.ProductManagement;\nusing AAM.ProductManagement.Core.IRepository;\nusing AAM.Repository.EntityFramework;\n<#//修改命名空间#>\nnamespace AAM.ProductManagement.Repository\n{\n<#\n   // insert your template code here the template code will be syntax highlighted \n   // and you will have intellisense for all namespaces in the full edition\n   string solutionsPath = Host.ResolveAssemblyReference(\"$(SolutionDir)\");  \n   //修改此处路径即可生成实体\n   string modelDir=solutionsPath+\"\\\\AAM.ProductManagement.Core\\\\Models\\\\ProductManagement\\\\\";\n   string [] filesPaths=Directory.GetFiles(modelDir,\"*\",SearchOption.AllDirectories);\n\n    foreach (var item in filesPaths)\n    {\n\t\tFileInfo file=new FileInfo(item);\n\t\tstring className=file.Name.Replace(\".cs\",\"\");\n\t\tif(className.EndsWith(\"Context\")) continue;\n\t\t#>\n\n\n\tpublic partial class <#= className #>Repository: RepositoryBase<<#= className #>>, I<#= className #>Repository\n\t{\n\t\tpublic <#= className #>Repository(IProductManagementUnitOfWork unitOfWork):base(unitOfWork)\n\t\t{\n\n\t\t}\n\t}\n\t\t<#\n\t}\n#>\n}\n```\n\n这是一个用于快速生成仓储代码的模板。模板代码看起来相当复杂，如果不熟悉T4的语法，基本上是无法看懂，并且这种模板是无法直接调试的，你压根不知道你写的有没有问题，只有把整个模板渲染出来后才再编译一下才知道有没有问题。\n\n总结一下，2个问题：\n1. 调试不方便\n2. 有一定维护成本及学习成本\n\n为了解决上述问题，dotnet template engine用了另外一种思路：\n\n**模板即代码**\n\n你开发的模板首先必须是一个可以编译运行的代码，其次他才是一个模板。\n\n\n## 模板配置\n\n### 前置工作\n每一个模板项目的根目录都必须有一个.template.config目录,再这个目录下面必须有一个template.json配置问题，如下：\n\n\n| Member            | Type          | Description |\n| ----------------- | ------------- | ----------- |\n| `$schema`         | URI           | The JSON schema for the *template.json* file. Editors that support JSON schemas enable JSON-editing features when the schema is specified. For example, [Visual Studio Code](https://code.visualstudio.com/) requires this member to enable IntelliSense. Use a value of `http://json.schemastore.org/template`. |\n| `author`          | string        | The author of the template. |\n| `classifications` | array(string) | Zero or more characteristics of the template that a user might use to find the template when searching for it. The classifications also appear in the *Tags* column when it appears in a list of templates produced by using the `dotnet new -l|--list` command. |\n| `identity`        | string        | A unique name for this template. |\n| `name`            | string        | The name for the template that users should see. |\n| `shortName`       | string        | A default shorthand name for selecting the template that applies to environments where the template name is specified by the user, not selected via a GUI. For example, the short name is useful when using templates from a command prompt with CLI commands. |\n| `sourceName`       | string        | The name in the source tree to replace with the name the user specifies. The template engine will look for any occurrence of the `sourceName` mentioned in the config file and replace it in file names and file contents. The value to be replaced with can be given using the `-n` or `--name` options while running a template. If no name is specified, the current directory is used.|\n| `preferNameDirectory`       | boolean        | Indicates whether to create a directory for the template if name is specified but an output directory is not set (instead of creating the content directly in the current directory). The default value is false.|\n\n这个是template.json配置中各个字段的简要说明，下面会对几个关键字段进行介绍\n\n### sourceName\n\n如果将sourceName定义为AAA，那么在这个模板中所有以打头AAA文件名或包含AAA文本内容都会被自动替换掉，如\n\n```\ndotnet new -n BBB\n```\n那么 AAA会被替换为BBB，相关文件也会被重命名。一般来讲，sourceName的值就是模板文件中的csproj文件名或者sln文件名\n\n\n### preferNameDirectory\n这个值一般会配置为true，eg：如果我在CCC目录下执行dotnet new命令，相当于 dotnet new  -n CCC\n\n\n### symbol 特殊变量替换\n上述两点并没有彻底解决变量替换的问题，我们需要让一些我们自己定义的变量也能够被替换掉，这个时候需要使用symbol配置,\n\n```\n\"symbols\": {\n        \"protoPackage\": {\n            \"type\": \"parameter\",\n            \"replaces\": \"_ProtoPackage_\",\n            \"datatype\": \"text\",\n            \"isRequired\": true,\n            \"description\": \"Provide the proto package name\",\n            \"FileRename\": \"_ProtoPackage_\"\n        },\n        \"protoService\": {\n            \"type\": \"parameter\",\n            \"replaces\": \"_ProtoService_\",\n            \"datatype\": \"text\",\n            \"isRequired\": true,\n            \"description\": \"Provide the proto service name\",\n            \"FileRename\": \"_ProtoService_\"\n        }\n    }\n```\n\n\n```\nsyntax = \"proto3\";\n\noption csharp_namespace = \"AAA\";\n\npackage _ProtoPackage_;\n\n// The service definition.\nservice _ProtoService_ {\n}\n```\n\n如上所示，通过定义symbol变量可以将grpc proto文件的报名和服务名替换掉\n\n### 小结\n只用上述的三个配置参数，个人可以满足90%的场景需求，模板定制，无非就是变量替换，对于一些其他的场景微软官方也提供了相应的[例子](https://github.com/dotnet/dotnet-template-samples)\n\n\n\n\n\n\n\n\n## 模板发布、安装、卸载\n\n\n一般说来，模板开发完后我们会讲模板存放到内部的nuget服务器，为此，新建另外一个新的项目，来对模板文件打包，注意这里我们新建一个新的项目仅仅是为了将我们的模板内容传到nuget服务器，这个新建项目不是模板。\neg，项目结构如下：\n```\nproject_folder\n│   MyDotnetTemplates.csproj\n│\n└───templates\n    ├───mytemplate1\n    │   │   console.cs\n    │   │   readme.txt\n    │   │\n    │   └───.template.config\n    │           template.json\n    │\n    └───mytemplate2\n        │   otherfile.cs\n        │\n        └───.template.config\n                template.json\n```\n\nMyDotnetTemplates.csproj内容如下：\n```\n<Project Sdk=\"Microsoft.NET.Sdk\">\n\n  <PropertyGroup>\n    <PackageType>Template</PackageType>\n    <PackageVersion>1.0</PackageVersion>\n    <PackageId>AdatumCorporation.Utility.Templates</PackageId>\n    <Title>AdatumCorporation Templates</Title>\n    <Authors>Me</Authors>\n    <Description>Templates to use when creating an application for Adatum Corporation.</Description>\n    <PackageTags>dotnet-new;templates;contoso</PackageTags>\n    <TargetFramework>netstandard2.0</TargetFramework>\n\n    <IncludeContentInPack>true</IncludeContentInPack>\n    <IncludeBuildOutput>false</IncludeBuildOutput>\n    <ContentTargetFolders>content</ContentTargetFolders>\n  </PropertyGroup>\n\n  <ItemGroup>\n    <Content Include=\"templates\\**\\*\" Exclude=\"templates\\**\\bin\\**;templates\\**\\obj\\**\" />\n    <Compile Remove=\"**\\*\" />\n  </ItemGroup>\n\n</Project>\n```\ntemplates存发的是模板内容，用户如果执行\n```\ndotnet new -i AdatumCorporation.Utility.Template\n```\n那么就会获得模板，\n同理,通过以下命令可以删除模板内容\n\n```\ndotnet new -u AdatumCorporation.Utility.Template\n```\n\n\n\n## 参考\n[how to create your own templates for dotnet new](https://devblogs.microsoft.com/dotnet/how-to-create-your-own-templates-for-dotnet-new/)\n\n[custom-templates](https://github.com/dotnet/docs/edit/master/docs/core/tools/custom-templates.md)"},{"title":"如何Swashbuckle可以动态的增加EndPoint","url":"/2020/12/23/如何让Swashbuckle可以动态的增加EndPoint/","content":"\n## 问题背景\n\n不得不说[MMLib.SwaggerForOcelot](https://github.com/Burgyn/MMLib.SwaggerForOcelot)这个Ocelot Swagger插件是真的好用，可以很方便的集成下游服务的swagger.json到网关之中，极大的简化了客户端的调试工作。但是这个插件有一个致命的缺陷，那就是无法动态的支持下游结点。也就是说如果下游增加一个新的结点，如果你想把这个结点swagger带出来的话，那么就必须重启ocelot。\n[这个issue](https://github.com/domaindrivendev/Swashbuckle.AspNetCore/issues/1093)也提到了这个问题，作者大概的意思就是说，没办法实现，要改的东西太多了，那么究竟有没有办法实现这个动态加载swagger的功能呢？答案是有\n\n\n\n## 分析问题\n\n先回忆一下我们平时我们集成swagger的常见写法\n\n\n```\n   public void ConfigureServices(IServiceCollection services)\n   {\n        services.AddSwaggerGen(c => .....);\n   }\n    public void Configure(IApplicationBuilder app, IWebHostEnvironment env)\n    {\n          app.UseSwagger();\n          app.UseSwaggerUI(options =>\n          {\n             options.SwaggerEndpoint(\"/swagger/v1/swagger.json\", \"XXX API V1\");\n          });\n    }\n```\n\n翻一下Swashbuckle的源码：\n\n```\n   public static IApplicationBuilder UseSwaggerUI(\n            this IApplicationBuilder app,\n            Action<SwaggerUIOptions> setupAction = null)\n        {\n            var options = new SwaggerUIOptions();\n            if (setupAction != null)\n            {\n                setupAction(options);\n            }\n            else\n            {\n                options = app.ApplicationServices.GetRequiredService<IOptions<SwaggerUIOptions>>().Value;\n            }\n\n            app.UseMiddleware<SwaggerUIMiddleware>(options);\n\n            return app;\n        }\n```\n\n注意到 SwaggerUIMiddleware的构造函数：\n```\n  public class SwaggerUIMiddleware\n        public SwaggerUIMiddleware(\n            RequestDelegate next,\n            IHostingEnvironment hostingEnv,\n            ILoggerFactory loggerFactory,\n            SwaggerUIOptions options)\n        {\n            _options = options ?? new SwaggerUIOptions();\n\n            _staticFileMiddleware = CreateStaticFileMiddleware(next, hostingEnv, loggerFactory, options);\n\n            _jsonSerializerOptions = new JsonSerializerOptions();\n            _jsonSerializerOptions.PropertyNamingPolicy = JsonNamingPolicy.CamelCase;\n            _jsonSerializerOptions.IgnoreNullValues = true;\n            _jsonSerializerOptions.Converters.Add(new JsonStringEnumConverter(JsonNamingPolicy.CamelCase, false));\n        }\n\n```\n\n那么无法使用dynamic endpoint的原因很明显，因为\n```\n app.UseMiddleware<SwaggerUIMiddleware>(options);\n```\n上面这句话本质上是把这个SwaggerUIMiddleware注册成一个单例，也就是说他的构造函数只会执行一次。那么你后续取到的endpoint必然就是一个“静态”的东西，那么解决这个主要矛盾就行了\n\n\n\n\n### 解决思路\n\n这里只是阐述思路，具体的实践方法可以自己去尝试：\n\n首先我们通过一个scope configurer，每一个http请求都会触发swaggeruioptions的重新config\n\n\n```\nservices.AddScoped<IConfigureOptions<SwaggerUIOptions>, SwaggerUIOptionsConfigure>();\n```\n这样一来可以让SwaggerUIOptions动态的变化\n\n\n然后，我们必须把SwaggerUIMiddleware替换掉，也就是说，我们没必要这样写：\n```\napp.UseSwagger();\n          app.UseSwaggerUI(options =>\n          {\n             options.SwaggerEndpoint(\"/swagger/v1/swagger.json\", \"XXX API V1\");\n          });\n```\n\n我们可以开发一个新的中间件来替换掉把SwaggerUIMiddleware，eg:RenderSwaggerUI\n\n```\n\n public class RenderSwaggerUI : IMiddleware\n {\n   public RenderSwaggerUI(IWebHostEnvironment hostingEnv,\n            ILoggerFactory loggerFactory,\n            IOptionsSnapshot<SwaggerUIOptions> swaggerUIOptions,\n            IOptionsSnapshot<List<RouteOptions>> routes,\n            IOptionsSnapshot<SwaggerForOcelotUIOptions> swaggerForOcelotUIOptions,\n            IOptionsSnapshot<List<SwaggerEndPointOptions>> swaggerEndPoints,\n            IHttpClientFactory httpClientFactory,\n            ISwaggerJsonTransformer swaggerJsonTransformer, ISwaggerServiceDiscoveryProvider swaggerServiceDiscoveryProvider)\n        {\n            this.hostingEnv = hostingEnv;\n            this.loggerFactory = loggerFactory;\n            this.swaggerUIOptions = swaggerUIOptions.Value;\n            this.swaggerForOcelotUIOptions = swaggerForOcelotUIOptions.Value;\n            this.httpClientFactory = httpClientFactory;\n            this.swaggerJsonTransformer = swaggerJsonTransformer;\n            this.swaggerEndPoints = swaggerEndPoints.Value;\n            this.routes = routes.Value;\n            this.swaggerServiceDiscoveryProvider = swaggerServiceDiscoveryProvider;\n        }\n    public async Task InvokeAsync(HttpContext context, RequestDelegate next)\n    {\n\n            var swaggerUIMiddleware = new SwaggerUIMiddleware(next, this.hostingEnv, this.loggerFactory, this.swaggerUIOptions);\n            await swaggerUIMiddleware.Invoke(context);\n    }\n}\n\n```\n\n注意到这里RenderSwaggerUI实现IMiddleware，目的是让这个中间件被自动注册成一个scope中间件，每次都会执行构造函数.然后手动 new 一个 swaggerUIMiddleware并Invoke\n\n\n\n### 结论\n\nSwashbuckle的dynamic endpoint是可以实现的，只不过比较绕，这种方法不是最优解，但是可以解决问题。期待后续作者解决这个问题。\n\n\n\n\n\n### 参考\n\n[Dependency injection in ASP.NET Core](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-5.0)"},{"title":"rxjs中tap,map,switchmap的区别","url":"/2020/10/26/rxjs中tap,map,switchmap的区别/","content":"\n## 前言\n在前端三大框架angular,react,vue中，angular是唯一一个对rxjs进行了深度集成的框架。rxjs通过大量内置operator，极大的简化了前端对事件流的处理。\n\n对于一个.NET后端开发来说，上手rxjs不算难事，rxjs的operator都能在Linq上面找到对应的原型，\n所以说对于有志于成为全栈的.NET开发，angular是一个不错的选择。\n\n在angular开发过程中，tap,map,switchmap（经常被用来做限流）这三个operator的出场率很高，但由于这三个operator的命名很相似，经常容易搞混。这里简单介绍下这三个operator的区别\n\n\n### tap\ntap，并不会返回一个新的observable，只是对observable的stream进行预处理，如在调试过程中，我们经常会用tap把stream中的元素先打印出来，观测处理前和处理后的结果。\n\n\n```\nimport { from } from \"rxjs\";\nimport { tap } from \"rxjs/operators\";\n\nfrom([1, 2, 3])\n  .pipe(tap(item =>  /* do something */))\n  .subscribe(item => console.log(item));\n```\ntap类似于Rx.NET中的do operator\n### map\nmap，对input stream进行处理，并返回一个新的observable\n\n\n```\nimport { from } from 'rxjs';\nimport { map } from 'rxjs/operators';\n\nfrom([1, 2, 3])\n  .pipe(map((item) => item + 2))\n  .subscribe((item) => console.log(item));\n```\n\nmap类似于Rx.NET中的select operator\n\n\n\n### switchMap\n\n将一个内嵌的observable做flatten处理。\n\n```\nimport { from } from 'rxjs';\nimport { map } from 'rxjs/operators';\n\nfrom([1, 2, 3])\n  observable as return value.\n itself is a new observable now,\n  .pipe(map((item) => methodWhichReturnsObservable(item)))\n  .subscribe((item) => console.log(item));\n```\n在上述代码中如果methodWhichReturnsObservable也是返回一个observable，那么console.log(item) 打印出来的item并不是一个number，而是一个observable。\n\n为了处理这一种情况，只需将map改成switchmap\n\nswitchmap类似于Rx.NET中的selectmany\n\n\n\n```\nimport { from } from \"rxjs\";\nimport { switchMap } from \"rxjs/operators\";\n\nfrom([1, 2, 3])\n  .pipe(switchMap(item => methodWhichReturnsObservable(item))\n  .subscribe(resultItem => console.log(resultItem));\n```\n\n\n\n## 参考\n\n[Rx Operators](http://reactivex.io/documentation/operators.html)"},{"title":"Grpc Channel没有关闭而导致的内存泄露问题排查","url":"/2020/09/22/GrpcChannel没有正常关闭而导致的内存泄露问题排查/","content":"\n## 背景\n日前上线了一个用于统计统计用户活跃度的服务，上线之后，出现了内存泄漏的问题，通过lldb对程序的core dump进行分析，最终找到了泄漏的原因\n\n\n\n## 分析\n服务上线后，出现大量告警，提示服务器内存不足，grafana监控提示服务内存泄漏：\n\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/WeChat%20Screenshot_20200922084321.png)\n\n\n使用将线上的服务的内存dump下来，继续观察：\n\n```\n/usr/share/dotnet/shared/Microsoft.NETCore.App/2.1.1/createdump -u 1\n```\n\n\n\n通过lldb加载core dump文件：\n\n```\nlldb-3.9 dotnet -c /tmp/20290824_activevalue_coredump  -o \"plugin load /usr/share/dotnet/shared/Microsoft.NETCore.App/2.1.1/libsosplugin.so\"\n```\n\n\n查看堆大小：\n\n```\neeheap -gc\n```\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/WeChat%20Screenshot_20200927023535.png)\n\n\n进一步查看当前堆各个类型的对象数量\n``` dumpheap -stat ```\n\n提示有大量Grpc对象积压.\n\n进一步，对项目的各个接口进行压测,对内存进行三次采样：\n\n第一次采样77MB:\n\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/dasdasdas.png)\n\n\n\n\n第二次采样82MB:\n\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/2323fadas.png)\n\n\n\n第三次采样 86MB：\n\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/adasdasgdfasdas.png)\n\n\n\nVS内存分析工具提示GRPC内存对象一直没有得到有效的控制，数量不断上升\n在采样过程中手动进行GC，只是下降53个对象，大量channel仍然驻留内存:\n\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/dasdasfdvfsdvsdf.png)\n\n\n\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/dasdascas.png)\n\n\n\n\n根据上述采样分析，可以肯定业务代码中存在grpc channel正常关闭的场景。\n\n\n进一步查看代码发现：\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/WeChat%20Screenshot_20200927024147.png)\n\n每一次通过grpc client调用其他服务的时候会直接常见Channel，而不是复用之前的Channel，并且创建后的Channel没有关闭\n\n\n修复这部分代码后，线上内存使用率恢复正常\n\n\n\n## 参考\n\n[Channel creation best practice](https://github.com/grpc/grpc-java/issues/3268)\n\n[Performance best practices with gRPC](https://docs.microsoft.com/zh-cn/aspnet/core/grpc/performance?view=aspnetcore-5.0)！！！"},{"title":"Union查询性能优","url":"/2020/09/21/Union查询性能优/","content":"\n## Union的工作原理\n\n假设现在有两个集合A：\n```\nblue\ngreen\ngray\nblack\n```\n集合B：\n```\nred\ngreen\nyellow\nblue\n```\n现在对集合A、B进行Union操作，首先Mysql会创建一个临时表来暂存A ∪ B = C\nStep1(将A的元素和B的元素都添加到C中)\n```\nblack\nblue\nblue\ngray\ngreen\ngreen\nred\nyellow\n```\n\n接下来对C进行去重，得到：\n```\nblack\nblue\ngray\ngreen\nred\nyellow\n```\n\n## 如何优化\n\n### 使用Union All\n\n对一个大数据集进行去重操作需要很高的算力，当业务场景可以接收重复结果的情况下，使用Union All，Union All不会对结果集进行去重，这个时候可以减少Union去重带来的性能损耗\n\n\n### 将查询条件放在Union的子查询中\n\n如果不将查询条件放在子查询之中，这个时候默认Union将各个子查询的结果全部查出来，然后放到一个临时表中，再对临时表进行过滤，这个时候，没办法利用到Mysql的索引，不利于性能的提高。所以使用Union操作的时候要尽量将查询条件，排序条件放在子查询之中。\n另外需要注意的一点是，如果直接对子查询进行Order By操作，Mysql会提示```Incorrect usage of UNION and ORDER BY```,如：\n```\nSELECT * FROM t1 WHERE username LIKE 'l%' ORDER BY score ASC\nUNION\nSELECT * FROM t1 WHERE username LIKE '%m%' ORDER BY score ASC\n```\n\n解决的办法就是用一个括号将子查询包起来，再进行Union操作：\n\n```\n(SELECT * FROM t1 WHERE username LIKE 'l%' ORDER BY sroce ASC)\nUNION\n(SELECT * FROM t1 WHERE username LIKE '%m%' ORDER BY score ASC)\n```\n\n## 参考\n[MySQL中union和order by同时使用的实现方法](https://www.jb51.net/article/99842.htm)\n\n[How to Optimize MySQL UNION For High Speed](https://www.iheavy.com/2013/06/13/how-to-optimize-mysql-union-for-high-speed/)"},{"title":"ThreadLocal的应用","url":"/2020/09/14/ThreadLocal在RabbitMq中的应用/","content":"## 基本概念\n\n### Thread-Local Storage\n\n在日常开发过程中，你有时候可能会希望一些对象，变量可以做到线程隔离，不相互影响。为了实现这个需求，.NET引入了一个被称为`Thread-Local Storage` 的概念，通过`Thread-Local Storage`，变量、对象无需重复定义，也不需要添加锁，就可以实现在线程之间的相互隔离\n\n\n### ThreadLocal<T>\n\n`ThreadLocal` 是 `Thread-Local Storage`的一个具体实现，一个`ThreadLocal`的对象字段，在不通线程之中可以做到相互隔离\n\n示例代码：\n\n```\nclass Program\n    {\n        static void Main(string[] args)\n        {\n            // contruct on this thread\n            ThreadLocalDemo demoObject = new ThreadLocalDemo();\n            demoObject.PrintCounterValue();\n            demoObject.IncrementCounter();\n            demoObject.PrintCounterValue();\n\n          \n            var resetEvent = new ManualResetEvent(false);\n            ThreadPool.QueueUserWorkItem(state =>\n            {\n             \n                ((ThreadLocalDemo)state).PrintCounterValue();\n                ((ThreadLocalDemo)state).IncrementCounter();\n                ((ThreadLocalDemo)state).PrintCounterValue();\n\n              \n                var demo = new ThreadLocalDemo();\n                demo.IncrementCounter();\n                demo.PrintCounterValue();\n\n                resetEvent.Set();\n            }, demoObject);\n\n            resetEvent.WaitOne();\n        }\n    }\n\n    public class ThreadLocalDemo\n    {\n        private ThreadLocal<int> counter;\n        private static ThreadLocal<int> staticCounter;\n        private static Guid staticId;\n        private Guid id;\n\n        static ThreadLocalDemo()\n        {\n            staticCounter = new ThreadLocal<int>();\n            staticId = Guid.NewGuid();\n            Console.WriteLine($\"Static constructor:\");\n            Console.WriteLine($\"thread id: {Thread.CurrentThread.ManagedThreadId}, type id: {staticId}\");\n        }\n\n        public ThreadLocalDemo()\n        {\n            counter = new ThreadLocal<int>();\n            id = Guid.NewGuid();\n            Console.WriteLine($\"Constructor: thread id: {Thread.CurrentThread.ManagedThreadId}, object id {id}\");\n        }\n\n        public void IncrementCounter()\n        {\n            Console.WriteLine(\"Incrementing both local and static counters\");\n            counter.Value++;\n            staticCounter.Value++;\n        }\n\n        public void PrintCounterValue()\n        {\n            Console.WriteLine(\"Printing current values\");\n            Console.WriteLine($\"thread id: {Thread.CurrentThread.ManagedThreadId}, object id {id}, counter: {counter.Value}, static Counter: {staticCounter.Value}\");\n        }\n    }\n```\n\n输出结果：\n\n```\nStatic constructor:\nthread id: 1, type id: 220a1d54-0d32-4961-9f19-9da5a625eaeb\nConstructor: thread id: 1, object id a655a69c-4c16-4a6e-88b3-c339f247d895\nPrinting current values\nthread id: 1, object id a655a69c-4c16-4a6e-88b3-c339f247d895, counter: 0, static Counter: 0\nIncrementing both local and static counters\nPrinting current values\nthread id: 1, object id a655a69c-4c16-4a6e-88b3-c339f247d895, counter: 1, static Counter: 1\nPrinting current values\nthread id: 4, object id a655a69c-4c16-4a6e-88b3-c339f247d895, counter: 0, static Counter: 0\nIncrementing both local and static counters\nPrinting current values\nthread id: 4, object id a655a69c-4c16-4a6e-88b3-c339f247d895, counter: 1, static Counter: 1\nConstructor: thread id: 4, object id 3175a74e-255c-4934-ae9f-e9790d05e486\nIncrementing both local and static counters\nPrinting current values\nthread id: 4, object id 3175a74e-255c-4934-ae9f-e9790d05e486, counter: 1, static Counter: 2\n```\n\n\n上述代码，所在demoObj的实例计数器在Thread 1 为 1，但当进入到Thread 4 的时候，实例计数器被重置为0，也就是说`counter`的值受线程影响，不同的线程有不同的拷贝\n\n## 具体应用\n\n\n`ThreadLocal`目前在自己维护的项目中应用的比较少，大多数情况会选择在线程上下文中定义一个新的变量，而不是去引用外部的`ThreadLocal`变量，目前唯一用到的就是在RabbitMQ。\n\n根据RabbitMQ的官方文档，IModel对象不是一个线程安全的对象，每一个每一个线程应该有且只有一个IModel,建多了也没意义：\n\n\n```\nDon’t share channels between threads\nUse one channel per thread in your application, and make sure that you don’t share channels between threads as most clients don’t make channels thread-safe.\n\nCloudAMQP allows you to scale your instances to meet demand while providing mechanisms to troubleshoot leaks. If you have any questions, you can reach out to us at support@cloudamqp.com\n```\n\n\n```\n  public interface IMessagePublisher\n    {\n        Task PublishAsync<TMessage>(TMessage message);\n    }\n\n    public class MessagePublisher : IMessagePublisher\n    {\n\n        private readonly ISerializer _serializer;\n        public MessagePublisher(ISerializer serializer, IConnectionFactory connectionFactory)\n        {\n            _serializer = serializer;\n            _channel = new ThreadLocal<IModel>(() => connectionFactory.CreateConnection().CreateModel());\n        }\n\n        public async Task PublishAsync<TMessage>(TMessage message)\n        {\n            var type = typeof(TMessage);\n            var exchangeName = GetExchangeName(type);\n            var routingKey = GetRoutingKey(type);\n            var data = _serializer.Serialize(message);\n\n            await PublishAsync(exchangeName, routingKey, data);\n        }\n    }\n    \n     services.AddSingleton<IMessagePublisher, MessagePublisher>();\n```\n\n通过上述代码，虽然IMessagePublisher是单例，但channel也可以实现做到每一个线程唯一，最大程度的减少了对象的创建\n\n\n## 参考\n\n[What is the relationship between connections and channels in RabbitMQ?](https://www.cloudamqp.com/blog/2019-11-13-the-relationship-between-connections-and-channels-in-rabbitmq.html)"},{"title":"基于 kubernetes 的动态 jenkins slave的自动化发布","url":"/2020/08/10/基于 kubernetes 的动态 jenkins slave的自动化发布/","content":"\n# 背景\n前几天在youtube上面看了一个关于如何[使用jenkins实现k8s的CI/CD](https://www.youtube.com/watch?v=eMOzF_xAm7w&t=3s),现对视频中相关的配置方法进行了文字性的总结，并在此基础上引入了sematic release实现版本号的自动生成\n\n## jenkins 动态 slave\n持续构建与发布是我们日常工作中必不可少的一个步骤，目前大多公司都采用 Jenkins 集群来搭建符合需求的 CI/CD 流程，然而传统的 Jenkins Slave 一主多从方式会存在一些痛点，比如：\n\n主 Master 发生单点故障时，整个流程都不可用了\n每个 Slave 的配置环境不一样，来完成不同语言的编译打包等操作，但是这些差异化的配置导致管理起来非常不方便，维护起来也是比较费劲\n资源分配不均衡，有的 Slave 要运行的 job 出现排队等待，而有的 Slave 处于空闲状态\n资源有浪费，每台 Slave 可能是物理机或者虚拟机，当 Slave 处于空闲状态时，也不会完全释放掉资源。\n正因为上面的这些种种痛点，我们渴望一种更高效更可靠的方式来完成这个 CI/CD 流程，而 Docker 虚拟化容器技术能很好的解决这个痛点，又特别是在 Kubernetes 集群环境下面能够更好来解决上面的问题，下图是基于 Kubernetes 搭建 Jenkins 集群的简单示意图：\n![image](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/clipboard.png)\n\n## helm\nKubernetes是容器集群管理系统，每个成功的软件平台都有一个优秀的打包系统，比如 Debian、Ubuntu 的 apt，Redhat、Centos 的 yum。而 Helm 则是 Kubernetes 上的包管理器。helm相当于一个应用商店，将一个在云上部署的应用相关的组件全部打包起来，进行安装、升级、管理等，如下图所示：\n![image](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/clipboard%20(1).png)\n\n### HelmClient \n是用户命令行工具，其主要负责如下：\n- 本地 chart 开发\n- 仓库管理\n- 与 Tiller sever 交互\n- 发送预安装的 chart\n- 查询 release 信息\n- 要求升级或卸载已存在的 release\n\n### TillerServer\n是一个部署在 Kubernetes集群内部的 server，其与 Helm client、Kubernetes API server 进行交互。Tiller server 主要负责如下：\n- 监听来自 Helm client 的请求\n- 通过 chart 及其配置构建一次发布\n- 安装 chart 到 Kubernetes集群，并跟踪随后的发布\n- 通过与 Kubernetes交互升级或卸载 chart\n- 简单的说，client 管理 charts，而 server 管理发布 release\n\n\n## Semantic Release\n是一个自动生成版本号,发布日志的工具。semantic release按照\n[Semantic Versioning](https://semver.org/)的规范,根据用户的[commit message](https://github.com/angular/angular/blob/master/CONTRIBUTING.md)来确定下一个版本号\n\n# 配置\n\n## Jenkins\n\n### 安装Kubernetes插件\n\n![image](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/clipboard%20(2).png)\n\n### 配置kubernetes插件\n![image](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/clipboard%20(3).png)\n\n1.Kubernetes URL，API SERVER的URL\n\n2.Kubernetes server certificate key，证书密钥,可以在 ~/.kube/config 文件中获得\n\n3.Kubernetes Namespace，Slave Pod所在的Kubernetes namespace\n\n4.Credentials，访问API SERVER时使用的Token\n\n5.Jenkins URL，Jenkins Master节点的URL\n\n6.Jenkins Tunnel，Jenkins Tunnel地址\n\n7.授权,namespace与3保持一致\n\n```\n\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: jenkins\n---\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: jenkins\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\"]\n  verbs: [\"create\",\"delete\",\"get\",\"list\",\"patch\",\"update\",\"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods/exec\"]\n  verbs: [\"create\",\"delete\",\"get\",\"list\",\"patch\",\"update\",\"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"pods/log\"]\n  verbs: [\"get\",\"list\",\"watch\"]\n- apiGroups: [\"\"]\n  resources: [\"secrets\"]\n  verbs: [\"get\"]\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: RoleBinding\nmetadata:\n  name: jenkins\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: jenkins\nsubjects:\n- kind: ServiceAccount\n  name: jenkins\n```\n\n```\nkubectl create clusterrolebinding jenkins --clusterrole cluster-admin --serviceaccount=<namespace>:jenkins\n```\n\n\n\n\n\n# 发布配置\n\n## 目录结构\n![image](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/clipboard%20(4).png)\n\n1. charts目录，存放helm 模板文件\n2. src，项目代码\n3. .releaserc.json，semantci-release配置文件\n4. CHANGELOG.MD，发布日志，由semantic-release自动生成\n5. Jenkinsfile，Jenkins 流水线的定义文件\n\n## gitlab 集成\n\n![image](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/clipboard%20(5).png)\n\n## 创建Pipeline任务\n\n\n### 配置pipeline环境变量\n\n![image](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/clipboard%20(6).png)\n\n\n### 配置gitlab trigger\n\n![image](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/clipboard%20(7).png)\n\n注意：需要勾选**ci-skip**选项,防止自动生成changelog时重复触发CI\n\n\n### 配置Pipeline\n\n![image](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/clipboard%20(8).png)\n\n\n\n\n\n##  集成semantic-release\n\n```\n{\n    \"branch\": \"master\",\n    \"plugins\": [\n        \"@semantic-release/commit-analyzer\",\n        \"@semantic-release/release-notes-generator\",\n        [\n            \"@semantic-release/changelog\",\n            {\n                \"changelogFile\": \"CHANGELOG.md\",\n                \"changelogTitle\": \"# Changelog | Consul Kube Sync\"\n            }\n        ],\n        [\n            \"@semantic-release/git\",\n            {\n                \"assets\": [\n                    \"CHANGELOG.md\"\n                ],\n                \"message\": \"[ci-skip]\"\n            }\n        ],\n        [\n            \"@semantic-release/exec\",\n            {\n                \"prepareCmd\": \"echo ${nextRelease.version} > .next-version\"\n            }\n        ]\n    ]\n}\n\n``` \n\n##  jenkinsfile\n\n请参考备注示例项目\n\n\n\n# 备注\n\n[示例项目](https://github.com/LoremipsumSharp/JenkinsKubernetesAutomation)\n\n\n\n\n\n\n\n"},{"title":"DNS的一些入门的基本概念","url":"/2020/08/05/DNS的一些入门的基本概念/","content":"\n## Authoritative Servers\nDNS Servers can be configured to host more than one domain. A server can be primary for one domain, and secondary for another. The term authoritative refers to any DNS servers that has a complete copy of the domain's information, whether it was entered by an administrator or transferred from a primary server. Thus, a secondary server can and should be authoritative for any domain for which it performs secondary authoritative resolution.\n## Authoritative Responses\nAny response to a DNS query that originates from a DNS server with a complete copy of the zone file is said to be an 'authoritative response'. What complicates matters is that DNS servers cache the answers they receive. If a DNS server has an SOA record, it fills in a field in the response that signals that the server queried is authoritative for the domain and that the answer is authoritative. Any DNS server external to that domain that retrieved the authoritative response will cache that answer. The next time the server is queried, it will say that the answer it is giving is authoritative, even though it is not authoritative for that domain.\n\nIn other words, it IS possible for a DNS server that is NOT an authoritative server for a domain to give an 'authoritative response' to a DNS query for a domain it does not serve.\n\nNon-authoritative responses come from DNS servers that have cached an answer for a given host, but received that information from a server that is not authoritative for the domain.\n\n\n## Kind of DNS Server\nDNS architecture works on an inverted tree structure. At the top of the inverted tree is the 13 DNS root servers, and then comes the TLD(Top Level Domain) servers, and beneath the TLD servers comes the authoritative DNS server for a particular domain(sometimes called as secondary domains.)\n\n\n## Kind of DNS Query\n[difference between iterative and recursive dns query](https://www.slashroot.in/difference-between-iterative-and-recursive-dns-query)\n\n\n## Dns Zone\n[What is a DNS ZONE file: A Complete Tutorial on zone file and its contents](https://www.slashroot.in/what-dns-zone-file-complete-tutorial-zone-file-and-its-contents)"},{"title":".NET内存管理中需要掌握的一些基本概念(持续更新）","url":"/2020/07/16/内存管理中需要掌握的一些基本概念/","content":"## Working set\nthis is a part of virtual address space that currently resides in the physical memory. This means it can be further divided into:\n- Private working set - consists of committed (private) pages in the\nphysical memory.\n- Shareable working set - consists of all shareable pages (no matter if they are actually shared or not)\n- Shared working set - consists of shareable pages that are actually\nshared with other processes.\n- Private bytes - all committed (private) pages - both in the physical and paged memory.\n- Virtual bytes - both committed (private) and reserved memory\n- Paged bytes - part of the virtual bytes that are stored in the page file.\n ![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/WeChat%20Screenshot_20200716021336.png)\n\n## Value Types\n\nWe have two categories of value types in the Common Language Specification:\n\n- structs - there are many built-in integral types (char, byte, integer, and so forth), floating-point types, and bool. And, of course, the user can define its own structs.\n- enumerations - they are basically an extension of integral types, becoming a type that consists of a set of named constants. From the memory-management point of view, they are just integral types so we won’t deal with them in this book at all as they are in fact structs also internally.\n\n\n## 使用struct的好处\n\n1. struct类型是Value Type，所以struct有可能被分配在stack上，分配在stack上可以避免因为分配的heap上所带来的gc\n2. strcut在同等条件下，所需的内存比class要小（这个是因为struct不需要存放相关的元信息）\n3. struct更加符合data locality的要求,refernce type 总是包含两个额外的字段，给定一个64B的cache line,refernce type命中缓存的概率远低于strcut\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/WeChat%20Screenshot_20200716025533.png)\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/WeChat%20Screenshot_20200716025454.png)\n\n## Lexical Scope\nIn the simplest words,it defines areas of code in which the given variable is visiable"},{"title":"在Kafka流处理中自定义时间窗口","url":"/2020/07/05/Kafka流处理中自定义时间窗口/","content":"## 问题的背景\n近期有一个项目在做重构，一部分业务要迁移到Kafka上面来进一步提高性能，需求是这样的：根据一定规则量化用户行为并实时统计用户活跃度，每一个统计周期1天，即24小时。\n\n咋一看，这个问题很好处理，直接使用Kafka流处理中的时间窗口函数，每一个窗口的长度为24小时，每次接收到一条消息就通过Kafka Stream Api进行聚合，时间窗口可以直接使用Tumbling Windows来解决。但是产品还提出了另外一个需求，就是统计时间范围，从每天的22:00 ~ 第二天的21:59\n\n这种情况，无法用Tumbling windows来解决，因为Tumbling windows定义的时间范围是从每天的（00:00~23:59)，Kafka的相关文档也没又提到这个场景需要如何处理。\n\n\n## 实现方法\n实际上，这个需求可以通过一下两种方法：\n1. 通过Timeextractor来重写时间\n2. 自定义时间窗口\n\n\n### 通过TimeExtractor来重写时间戳\n\n既然产品需求是从每天的22:00 ~ 第二天的21:59，那么我可以在原有的时间戳的基础上加两个小时来补全Tumbling windows所定义的时间范围\n\n```\npublic class UserEventTimestampExtractor implements TimestampExtractor {\n\n    @Override\n    public long extract(ConsumerRecord<Object, Object> record, long partitionTime) {\n        UserEvent userEvent = (UserEvent) record.value();\n        return userEvent.getCreateTime().plusHours(2)\n        .toInstant(ZoneOffset.UTC).toEpochMilli();\n    }\n\n}\n```\n\n### 自定义时间窗口（建议使用，更加直观）\n\n继承 Windows<TimeWindow> 并重写 windowsFor 方法\n\n\n```\n    @Override\n    public Map<Long, TimeWindow> windowsFor(final long timestamp) {\n        final Instant instant = Instant.ofEpochMilli(timestamp);\n\n        final ZonedDateTime zonedDateTime = instant.atZone(zoneId);\n        final ZonedDateTime startTime = zonedDateTime.getHour() >= startHour ? zonedDateTime.truncatedTo(ChronoUnit.DAYS).withHour(startHour) : zonedDateTime.truncatedTo(ChronoUnit.DAYS).minusDays(1).withHour(startHour);\n        final ZonedDateTime endTime = startTime.plusDays(1);\n\n        final Map<Long, TimeWindow> windows = new LinkedHashMap<>();\n        windows.put(toEpochMilli(startTime), new TimeWindow(toEpochMilli(startTime), toEpochMilli(endTime)));\n        return windows;\n    }\n```\n这里的starhour取22\n\n\n## 参考\n[kafka-streams-examples](https://github.com/confluentinc/kafka-streams-examples/blob/5.5.0-post/src/test/java/io/confluent/examples/streams/window/DailyTimeWindows.java)\n"},{"title":"如何安装特定版本的dotnet sdk","url":"/2020/06/25/如何安装特定版本的dotnet sdk/","content":"在ubuntu上通过package mananger安装dotnet sdk默认情况下会自动安装最新版的,但有些时候我们并不希望安装最新版，而是安装一个特定的版本，这个时候可以通过一下三种方法：\n1. 执行[dotnet-install](https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-install-script) 并指定特定版本号，如:\n\n```\n./dotnet-install.sh --version 3.1.201\n```\n\n\n2. 手动下载二进制tar包并解压（比较麻烦）\n3. 通过package mananger进行安装(官网目前没有介绍这种方法)\n\n```\n#首先查看目前可安装的包版本\napt policy dotnet-sdk-3.1\n#安装指定版本\napt-get install  dotnet-sdk-3.1=3.1.201-1\n```\n"},{"title":"Spring Data MongoDb 通过Gradle集成QureyDSL的配置方法","url":"/2020/05/17/Spring Data MongoDb 通过Gradle集成QureyDSL的配置方法/","content":"\n## 引言\nQueryDSL是一个通用的查询框架，专注于通过Java API构建类型安全的SQL查询。目前在 Github 上的发布的 Release 版本已经多达 251 个版本，目前最新版是 4.3.1 ，并且由 Querydsl Google组 和 StackOverflow 两个团队提供支持。QueryDSL 是一个框架，可用于构造静态类型的类似SQL的查询。可以通过诸如 QueryDSL 之类的 API 构造查询，而不是将查询编写为内联字符串或将其外部化为XML文件。\n\n例如，与简单字符串相比，使用 API 的好处是\n\n- IDE中的代码完成\n\n- 几乎没有语法无效的查询\n\n- 可以安全地引用域类型和属性\n\n- 更好地重构域类型的更改\n\n\n目前网上能够查阅到通过gradle集成QueryDSL的资料非常少，大部分是基于Maven，基于gradle的配置方法很多都是错的（这个是由于gradle的版本升级，新版本的gradle对QueryDSL没有做到向下兼容）\n\n\n## gradle配置方法\n\n\n\n```\nplugins {\n    id 'org.springframework.boot' version '2.2.5.RELEASE'\n    id 'io.spring.dependency-management' version '1.0.9.RELEASE'\n    id 'java'\n    id \"com.ewerk.gradle.plugins.querydsl\" version \"1.0.10\"\n\n}\n\ngroup = 'io.loremipsum'\nversion = '0.0.1-SNAPSHOT'\nsourceCompatibility = '11'\n\n\nrepositories {\n    mavenCentral()\n}\n\n\nquerydsl {\n    library = 'com.querydsl:querydsl-apt:4.1.4'\n    querydslSourcesDir = 'src/main/querydsl'\n    springDataMongo = true\n}\n\nsourceSets {\n    main {\n        java {\n            srcDirs = ['src/main/java', 'src/main/querydsl']\n        }\n    }\n}\n\n// 当gradle版本>5.0的时候需要加上这个配置\ncompileQuerydsl {\n    options.annotationProcessorPath = configurations.querydsl\n}\n\ndependencies {\n    compile 'org.springframework.boot:spring-boot-starter-data-mongodb'\n    compile 'org.springframework.boot:spring-boot-starter-web'\n\n    compile(\"com.querydsl:querydsl-core:4.1.4\")\n    compile(\"com.querydsl:querydsl-mongodb:4.1.4\")\n    compile(\"com.querydsl:querydsl-apt:4.1.4\")\n\n    compile 'org.projectlombok:lombok'\n    annotationProcessor 'org.projectlombok:lombok'\n\n    testCompile('org.springframework.boot:spring-boot-starter-test')\n    testCompile 'de.flapdoodle.embed:de.flapdoodle.embed.mongo'\n}\n```\n\n注意上述配置mongodb的依赖必须声明为compile（如果通过spring boot initializer创建项目,这里会被声明为implementation)，否则会提示：\n\n```\nAnnotation processor 'org.springframework.data.mongodb.repository.support.MongoAnnotationProcessor' not found\n```\n\n\n\n\n\n## 参考\n\n[Spring Boot （六）： 为 JPA 插上翅膀的 QueryDSL](https://www.cnblogs.com/babycomeon/p/11605809.html)\n\n[Querydsl Annotation Processor issue after upgrade to Gradle 5](https://stackoverflow.com/questions/53913274/querydsl-annotation-processor-issue-after-upgrade-to-gradle-5)\n\n[querydsl-plugin don't work in Gradle 5.0](https://github.com/ewerk/gradle-plugins/issues/108)"},{"title":"使用ValueTask减少假异步代码引起的GC","url":"/2020/04/27/使用ValueTask减少假异步代码引起的GC/","content":"## async/await代码存在的问题\nasync/await是.NET4.5引入的一个语法糖，如下所示，下面的代码首先会以同步的方法判断一个文件是否存在，如果存在，那么就会已异步的方式去读取文件的内容：\n\n```\npublic async Task<string> ReadFileAsync(string filename)\n{\n    if (!File.Exists(filename))\n        return string.Empty;\n    return await File.ReadAllTextAsync(filename);\n}\n```\n通过async/await开发人员可以编写更加简洁的异步代码，通过IL SPY我们可以观察到，编译器实际上将async/await转为为了一个StateMachine,如下所示：\n\n```\n[AsyncStateMachine(typeof(Program.<ReadFileAsync>d__14))]\npublic Task<string> ReadFileAsync(string filename)\n{\n    Program.<ReadFileAsync>d__14 <ReadFileAsync>d__;\n    <ReadFileAsync>d__.filename = filename;\n    <ReadFileAsync>d__.<>t__builder = AsyncTaskMethodBuilder<string>.\n    Create();\n    <ReadFileAsync>d__.<>1__state = -1;\n    AsyncTaskMethodBuilder<string> <>t__builder = <ReadFileAsync>d__.<>t__\n    builder;\n    <>t__builder.Start<Program.<ReadFileAsync>d__14>(ref <ReadFileAsync>d__);\n    return <ReadFileAsync>d__.<>t__builder.Task;\n}\n[CompilerGenerated]\n[StructLayout(LayoutKind.Auto)]\nprivate struct <ReadFileAsync>d__14 : IAsyncStateMachine\n{\n    void IAsyncStateMachine.MoveNext()\n    {\n        int num = this.<>1__state;\n        string result;\n        try\n        {\n            TaskAwaiter<string> awaiter;\n            if (num != 0)\n            {\n                if (!File.Exists(this.filename))\n                {\n                    result = string.Empty;\n                    goto IL_A4;\n                }\n                awaiter = File.ReadAllTextAsync(this.filename,\n                default(CancellationToken)).GetAwaiter();\n                if (!awaiter.get_IsCompleted())\n                {\n                    this.<>1__state = 0;\n                    this.<>u__1 = awaiter;\n                    this.<>t__builder.AwaitUnsafeOnCompleted<TaskAwaiter\n                    <string>, Program.<ReadFileAsync>d__14>(ref awaiter, ref\n                    this);\n                    return;\n                }\n        }\n        else\n        {\n            awaiter = this.<>u__1;\n            this.<>u__1 = default(TaskAwaiter<string>);\n            this.<>1__state = -1;\n        }   \n        result = awaiter.GetResult();\n    }\n    catch (Exception exception)\n    {\n        this.<>1__state = -2;\n        this.<>t__builder.SetException(exception);\n        return;\n    }\n\n    IL_A4:\n    this.<>1__state = -2;\n    this.<>t__builder.SetResult(result);\n    }\n}\n```\n\n注意到上面的代码，当文件不存在的时候会执行goto语句，也就是this.<>t__builder.SetResult(result)，t_builder是AsyncTaskMethodBuilder<T>的一个实例，\n我们可以看下SetResult的[实现](https://github.com/dotnet/runtime/blob/110282c71b3f7e1f91ea339953f4a0eba362a62c/src/libraries/System.Private.CoreLib/src/System/Runtime/CompilerServices/AsyncTaskMethodBuilderT.cs)\n\n```\npublic void SetResult(TResult result)\n{\n    // Get the currently stored task, which will be non-null if get_Task has already been accessed.\n    // If there isn't one, get a task and store it.\n    if (m_task is null)\n    {\n        m_task = GetTaskForResult(result);\n        Debug.Assert(m_task != null, $\"{nameof(GetTaskForResult)} should never return null\");\n    }\n    else\n    {\n        // Slow path: complete the existing task.\n        SetExistingTaskResult(m_task, result);\n    }\n}\n```\n由于此时这个时候并产生真正的异步操作，所以m_task is null 成立,查看GetTaskForResult(result)：\n\n```\n[MethodImpl(MethodImplOptions.AggressiveInlining)] \n// method looks long, but for a given TResult it results in a relatively small amount of asm\ninternal static Task<TResult> GetTaskForResult(TResult result)\n{\n    if (null != (object?)default(TResult)) // help the JIT avoid the value type branches for ref types\n    {\n        .....\n    }\n    else if (result == null) // optimized away for value types\n    {\n        return s_defaultResultTask;\n    }\n    return new Task<TResult>(result);\n    }\n}\n```\n由于string是引用类型且result不为null,所以必然会导致一个新的Task对象被创建，那么也就是说，即便不存在异步调用，也会创建一个新的Task对象，如果存在大量的假异步调用，势必会造成成大量的一代GC，从而影响程序的性能。\n\n## 问题的解决\n为了解决上述问题，.NET CORE 2.1引入了一个新的概念，ValueTask：\n\n```\npublic struct ValueTask<TResult>\n{\n\n    IValueTaskSource<TResult>\n    internal readonly object _obj;\n    internal readonly TResult _result;\n}\n```\n\n使用ValueTask改写ReadFile代码：\n\n```\npublic async ValueTask<string> ReadFileAsync(string filename)\n{\n    if (!File.Exists(filename))\n        return string.Empty;\n    return await File.ReadAllTextAsync(filename);\n}\n```\n当调用ReadFileAsync时，可以使用ValueTask.IsCompleted来判断这个调用是不是假异步调用，如下所示：\n\n```\nvar valueTask = ReadFileAsync();\nif(valueTask.IsCompleted)\n{\n    return valueTask.Result;\n}\nelse\n{\n    return await valueTask.AsTask();\n}\n```\n如果假异步调用，IsCompleted为true，这个时候返回valueTask.Result,不会产生Task对象的分配而ValueTask本身也是一个值类型，也不会产生allocation。反之，如果是真异步调用则按照原来的逻辑去执行。\n\n\n## 结论\n当应用程序对性能要求比较苛刻的时候并且存在大量假异步调用的情况下，可以考虑使用ValueTask来提高性能。"},{"title":"高并发场景下StackExchange.Redis驱动的超时问题","url":"/2020/04/25/高并发场景下StackExchange.Redis驱动的超时问题/","content":"## 问题背景\n近期部门的大量微服务在做国际化改造。为了实现国际化需求，需要有一个支撑服务用于提供用户ip信息数据。由于是支撑服务，会产生大量调用，大概每分钟2000次的调用，为了进一步提供性能，该服务会把用户的ip信息缓存到redis以避免重复调用第三方接口获取ip数据。\n上线前对该服务进行了压力测试，发现在高并发的场景下，会频繁发生\n**StackExchange.Redis.RedisTimeoutException**异常，这对于一个支撑服务来说是不可接受的。\n\n## 问题重现\n\n使用grpc压力测试工具[ghz](https://github.com/bojand/ghz)模拟高并发场景：\n\n```\n\tghz 192.168.1.44:43667 --insecure \\\n\t\t--proto ../../proto/FM.Region.Client/Region.proto \\\n\t\t--call Region.RegionSrv/GetRegionInfoDetailByIp \\\n  \t\t--concurrency 400 \\\n\t\t-n 1200 \\\n\t\t-D  ./ip.json\n\n```\n1200请求，400个并发，共3轮测试\n\n测试ip数据集如下：\n\n```\n[\n    {\n        \"IP\": \"27.220.195.252\"\n    },\n    {\n        \"IP\": \"32.213.120.200\"\n    },\n    {\n        \"IP\": \"58.88.5.142\"\n    },\n    {\n        \"IP\": \"99.107.218.202\"\n    },\n    {\n        \"IP\": \"126.179.177.51\"\n    },\n    {\n        \"IP\": \"75.179.58.40\"\n    },\n    {\n        \"IP\": \"92.243.129.145\"\n    },\n    {\n        \"IP\": \"179.240.146.239\"\n    },\n    {\n        \"IP\": \"54.99.209.135\"\n    },\n    {\n        \"IP\": \"116.125.57.197\"\n    },\n    {\n        \"IP\": \"104.243.227.11\"\n    },\n    {\n        \"IP\": \"65.175.113.237\"\n    },\n    {\n        \"IP\": \"92.160.105.28\"\n    },\n    {\n        \"IP\": \"51.189.156.232\"\n    },\n    {\n        \"IP\": \"101.136.19.162\"\n    },\n    {\n        \"IP\": \"128.78.227.70\"\n    },\n    {\n        \"IP\": \"123.139.77.54\"\n    },\n    {\n        \"IP\": \"172.234.209.119\"\n    },\n    {\n        \"IP\": \"187.172.248.233\"\n    },\n    {\n        \"IP\": \"28.8.211.1\"\n    },\n    {\n        \"IP\": \"130.96.236.81\"\n    },\n    {\n        \"IP\": \"88.162.103.72\"\n    },\n    {\n        \"IP\": \"166.2.94.121\"\n    },\n    {\n        \"IP\": \"102.106.115.156\"\n    },\n    {\n        \"IP\": \"19.148.120.200\"\n    },\n    {\n        \"IP\": \"219.240.103.98\"\n    },\n    {\n        \"IP\": \"221.17.125.56\"\n    },\n    {\n        \"IP\": \"91.236.176.82\"\n    },\n    {\n        \"IP\": \"41.237.239.70\"\n    },\n    {\n        \"IP\": \"145.55.30.213\"\n    },\n    {\n        \"IP\": \"139.135.98.132\"\n    },\n    {\n        \"IP\": \"72.143.86.138\"\n    },\n    {\n        \"IP\": \"198.225.10.195\"\n    },\n    {\n        \"IP\": \"136.234.70.30\"\n    },\n    {\n        \"IP\": \"103.89.118.202\"\n    },\n    {\n        \"IP\": \"44.250.218.13\"\n    },\n    {\n        \"IP\": \"116.207.166.76\"\n    },\n    {\n        \"IP\": \"140.238.239.80\"\n    },\n    {\n        \"IP\": \"31.158.163.164\"\n    },\n    {\n        \"IP\": \"182.215.64.241\"\n    },\n    {\n        \"IP\": \"220.197.147.157\"\n    },\n    {\n        \"IP\": \"117.254.129.148\"\n    },\n    {\n        \"IP\": \"94.184.10.88\"\n    },\n    {\n        \"IP\": \"219.61.223.175\"\n    },\n    {\n        \"IP\": \"185.172.199.161\"\n    },\n    {\n        \"IP\": \"184.69.18.249\"\n    },\n    {\n        \"IP\": \"166.64.229.72\"\n    },\n    {\n        \"IP\": \"212.98.0.204\"\n    },\n    {\n        \"IP\": \"160.59.24.87\"\n    },\n    {\n        \"IP\": \"48.195.150.66\"\n    },\n    {\n        \"IP\": \"147.186.60.20\"\n    },\n    {\n        \"IP\": \"138.19.147.96\"\n    },\n    {\n        \"IP\": \"8.43.149.29\"\n    },\n    {\n        \"IP\": \"108.94.149.179\"\n    },\n    {\n        \"IP\": \"111.177.253.182\"\n    },\n    {\n        \"IP\": \"99.160.130.179\"\n    },\n    {\n        \"IP\": \"125.194.19.83\"\n    },\n    {\n        \"IP\": \"26.100.156.127\"\n    },\n    {\n        \"IP\": \"105.18.80.126\"\n    },\n    {\n        \"IP\": \"128.141.4.89\"\n    },\n    {\n        \"IP\": \"80.20.225.251\"\n    },\n    {\n        \"IP\": \"41.253.214.98\"\n    },\n    {\n        \"IP\": \"36.5.58.33\"\n    },\n    {\n        \"IP\": \"56.52.122.254\"\n    },\n    {\n        \"IP\": \"162.240.161.83\"\n    },\n    {\n        \"IP\": \"195.221.65.187\"\n    },\n    {\n        \"IP\": \"223.215.140.121\"\n    },\n    {\n        \"IP\": \"42.254.253.187\"\n    },\n    {\n        \"IP\": \"99.236.88.173\"\n    },\n    {\n        \"IP\": \"87.49.237.85\"\n    },\n    {\n        \"IP\": \"124.230.221.226\"\n    },\n    {\n        \"IP\": \"46.22.123.116\"\n    },\n    {\n        \"IP\": \"105.85.140.56\"\n    },\n    {\n        \"IP\": \"69.167.167.233\"\n    },\n    {\n        \"IP\": \"176.44.47.123\"\n    },\n    {\n        \"IP\": \"40.225.1.63\"\n    },\n    {\n        \"IP\": \"102.209.225.101\"\n    },\n    {\n        \"IP\": \"62.173.169.38\"\n    },\n    {\n        \"IP\": \"51.133.22.72\"\n    },\n    {\n        \"IP\": \"31.129.69.30\"\n    },\n    {\n        \"IP\": \"194.133.28.78\"\n    },\n    {\n        \"IP\": \"9.243.223.78\"\n    },\n    {\n        \"IP\": \"185.107.13.97\"\n    },\n    {\n        \"IP\": \"155.131.137.219\"\n    }\n]\n```\n\n测试输出：\n\n```\n\n\n\nSummary:\n  Count:        1200\n  Total:        36.67 s\n  Slowest:      19.65 s\n  Fastest:      1.01 s\n  Average:      11.12 s\n  Requests/sec: 32.72\n\nResponse time histogram:\n  1011.354 [1]  |\n  2875.261 [8]  |∎\n  4739.167 [13] |∎\n  6603.074 [17] |∎∎\n  8466.981 [230]        |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  10330.887 [117]       |∎∎∎∎∎∎∎∎∎∎∎\n  12194.794 [440]       |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  14058.701 [172]       |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  15922.608 [145]       |∎∎∎∎∎∎∎∎∎∎∎∎∎\n  17786.514 [44]        |∎∎∎∎\n  19650.421 [7] |∎\n\nLatency distribution:\n  10%% in 8.15 s\n  25%% in 9.21 s\n  50%% in 11.17 s\n  75%% in 12.50 s\n  90%% in 14.51 s\n  95%% in 15.28 s\n  99%% in 17.24 s\n\nStatus code distribution:\n  [OK]                 1194 responses\n  [DeadlineExceeded]   6 responses\n\nError distribution:\n  [5]   rpc error: code = DeadlineExceeded desc = context deadline exceeded\n  [1]   rpc error: code = DeadlineExceeded desc = Deadline Exceeded\n```\n测试输出提示请求超时，而且大量请求响应时间很不理想，查看日志发现StackExchange.Redis.RedisTimeoutException异常：\n\n\n```\nStackExchange.Redis.RedisTimeoutException: Timeout performing EVAL, inst: 5, queue: 1032, qu: 0, qs: 1032, qc: 0, wr: 0, wq: 0, in: 97489, ar: 0, clientName: , serverEndpoint: 192.168.1.44:43667, keyHashSlot: 693 (Please take a look at this article for some common client-side issues that can cause timeouts: http:\\/\\/stackexchange.github.io\\/StackExchange.Redis\\/Timeouts)\\n   at StackExchange.Redis.ConnectionMultiplexer.ExecuteSyncImpl[T](Message message, ResultProcessor`1 processor, ServerEndPoint server ...\n```\n## 问题解决\n根据[StackExchange.Redis官方文档](https://github.com/StackExchange/StackExchange.Redis/blob/master/docs/Timeouts.md)描述,在高并发场景下，当StackExchange.Redis的内部线程池无法满足并发要求的时候会去请求CLR的全局线程池，全局线程池的初始线程数量是根据CPU的核心数来确定的，当全局线程池的线程不够用的时候，会以500ms/per thread的速度往线程池里面添加新的线程，但这个速度在高并发场景下还是远远不够的，为此需要配置CLR线程池的最小线程数来满足高并发的场景。\n在程序入口添加如下代码：\n\n```\nThreadPool.SetMinThreads(512, 100) //worker最小线程数512,IOCP最小线程数100\n```\n\n\n## 问题验证\n配置最小线程数后再进行压力测试，测试输出如下：\n\n```\nSummary:\n  Count:        1200\n  Total:        2.66 s\n  Slowest:      2.15 s\n  Fastest:      1.99 ms\n  Average:      827.12 ms\n  Requests/sec: 451.92\n\nResponse time histogram:\n  1.987 [1]     |\n  216.449 [66]  |∎∎∎∎∎∎∎\n  430.911 [174] |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  645.373 [403] |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  859.835 [136] |∎∎∎∎∎∎∎∎∎∎∎∎∎\n  1074.297 [75] |∎∎∎∎∎∎∎\n  1288.759 [48] |∎∎∎∎∎\n  1503.221 [69] |∎∎∎∎∎∎∎\n  1717.683 [156]        |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  1932.145 [13] |∎\n  2146.607 [59] |∎∎∎∎∎∎\n\nLatency distribution:\n  10%% in 332.77 ms\n  25%% in 445.91 ms\n  50%% in 547.70 ms\n  75%% in 1.28 s\n  90%% in 1.68 s\n  95%% in 1.91 s\n  99%% in 2.11 s\n\nStatus code distribution:\n  [OK]   1200 responses\n\n```\n超时问题消失,并且响应时间大幅度减小\n\n\n需要注意的是，如果机器配置不够（CPU跑满了)，再高并发场景下，仍然会出现超时问题。\n\n\n"},{"title":"记线上的一次Mysql死锁问题分析","url":"/2020/03/14/记线上的一次Mysql死锁问题分析/","content":"\n## 问题描述\n最近上线了叫做“F币”的功能，简单说下就是系统会根据用户每天在社区的活跃行为，计算每一个用户的活跃度，最后根据用户每天的总活跃度返还相应的“F币”给用户，用户得到F币之后可以在社区兑换不同的礼品,如下图所示：\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/BF0B1ABB-F459-4343-BE90-5177FB6583D5.png)\n\n在测试环境和仿真环境运行的好好的，但是上线之后经常接到用户反馈，需要多次点击才能完成领取。查看阿里云日志，提示数据库产生死锁，如下图所示：\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/9DF85AF7-0840-4323-9B0C-613480533A45.png)\n\n## 问题分析\n注意到这里有一排按钮，用户的每次点击，后台都会进行以下两个操作：\n1. 更新用户余额（用户表）\n2. 生成流水记录 （用户流水记录）\n\n注：用户表和流水表存在主外键关系\n\n以上的两个操作会放在同一个事务完成，并且由于Ef的SaveChanges并不会根据你代码执行的先后次序去更新数据库，当用户以很快的速度从左到右依次点击，存在以下可能：\n\nT1:事务A插入流水，由于存在外键，会对user对应的行上S锁。\n\nT2:事务B插入流水，由于存在外键，会对user对应的行上S锁。\n\nT3:事务A更新User的余额，请求行记录的X锁，被B事务在T2的S锁阻塞\n\nT4:事务B更新User的余额，请求行记录的X锁，被A事务在T1的S锁阻塞\n\n至此死锁产生。\n\n\n\n## 问题解决\n\n用了一个比较简单+暴力的方法：领取接口直接上redis分布式锁。\n\n\n## 总结与反思\n\n这个项目是使用DDD的思想进行开发的，自然而然地在ORM上面的选型使用了EntityFramework Code First,但是Code Firit在建表的时候会自做主张的在“多”端生成外键。对外键的使用，除开了一部分性能开销，就是上述的死锁问题，后续考虑把这部分重构为DbFirst。\n\n另外值得一提的是，后来对这部逻辑做了压测，发现这部分代码在Sql Server跑是没问题的，因为Sql Server在插入子表的时候不会对父表记录上锁，而Mysql会对父表上锁,所以产生了死锁，天下果然没有免费午餐！\n\n\n\n## 参考\n\n\n[DbContext SaveChanges Order of Statement Execution\n](https://stackoverflow.com/questions/7335582/dbcontext-savechanges-order-of-statement-execution)\n\n[Deadlock due to Foreign Key constraint](https://bugs.mysql.com/bug.php?id=48652)"},{"title":"AspNetCore2.1升级到3.1时CORS相关配置的变更","url":"/2020/02/27/AspNetCore2.1升级到3.1时CORS相关配置的变更/","content":"\n本周将公司的运营系统从AspNetCore2.1升级到了AspNetCore3.1,遇到了一些坑，这里记录以下\n\n## 2.1的相关CORS代码\n\n\n```csharp\npublic IServiceProvider ConfigureServices(IServiceCollection services)\n{\n\n        ... // 省略\n        services.AddCors(option => option.AddPolicy(\"corsPolicy\", builders =>\n        {\n            builders.AllowCredentials().AllowAnyOrigin().AllowAnyHeader().AllowAnyMethod();\n        }));\n        ... // 省略\n}\n\npublic void Configure(IApplicationBuilder app, ILoggerFactory loggerFactory, IHostingEnvironment env)\n{\n    ... // 省略\n    app.UseCors(\"corsPolicy\");\n     ... // 省略\n}\n```\n\n如果这部分代码这3.1的服务中不加任何修改，启动时提示错误：\n\n\n```\nThe CORS protocol does not allow specifying a wildcard (any) origin and credentials at the same time. Configure the CORS policy by listing individual origins if credentials needs to be supported.\n```\n\n\n这是由于在2.1之后,AspNetCore出于安全考虑，做了更加严格的限制，在不AllowCredentials()与AllowAnyOrigin()。\n\n假设现在站点A存在一个恶意脚本，而站点B存在一个比较的敏感的接口（如转账）。如果站点B作为服务端使用AllowCredentials()与AllowAnyOrigin()的同源配置，此时站点A可以直接调用站点B的敏感接口并发送凭证信息（如Cookie），那么将导致用户信息被窃取。\n\n\n\n## 3.1的相关CORS代码\n\n### options1 显示声明允许跨域的origin\n\n```csharp\nservices.AddCors(option => option.AddPolicy(\"corsPolicy\", builders =>\n            {\n                builders.WithOrigins(\"http://site.com\").AllowAnyHeader().AllowAnyMethod().AllowCredentials();\n            }));\n```\n\n\n### options2 使用 SetIsOriginAllowed（可以起到与AllowAnyOriginu一样的效果）\n\n\n```csharp\nservices.AddCors(option => option.AddPolicy(\"corsPolicy\", builders =>\n            {\n                builders.SetIsOriginAllowed(origin=>true).AllowAnyHeader().AllowAnyMethod().AllowCredentials(); //SetIsOriginAllowed(origin=>true)允许所有origin\n            }));\n```\n\n\n"},{"title":"InnodDB中的Gap Locks与Next-key Locks","url":"/2020/02/11/InnodDB中的Gap Locks与Next-key Locks/","content":"\n为了理解Gap Locks与Next-key Locks首先必须了解InnodDB定义的四种隔离级别\n\n## InnodDB的四种隔离级别\n\n1. Read uncommitted(未授权读取、读未提交)：如果一个事务已经开始写数据，则另外一个事务则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。这样就避免了更新丢失，却可能出现脏读。也就是说事务B读取到了事务A未提交的数据。\n2. Read committed（授权读取、读提交）： 读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。该隔离级别避免了脏读，但是却可能出现不可重复读。事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。\n3. Repeatable read（可重复读取,MySQL默认隔离级别）： 可重复读是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，即使第二个事务对数据进行修改，第一个事务两次读到的的数据是一样的。这样就发生了在一个事务内两次读到的数据是一样的，因此称为是可重复读。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。这样避免了不可重复读取和脏读，但是有时可能出现幻象读。（读取数据的事务）这可以通过“共享读锁”和“排他写锁”实现。\n4. Serializable（序列化）： 提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。序列化是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。 \n\n\n## Gap Locks\n如下图所示：假设存在一个索引(Key,pk),那么当innodb在一事务中中对(-∞,(9,5)]追加Gap Locks后,如果其他事务尝试在索引记录中的任意一个Gap添加记录,该事务将会被阻塞\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/WeChat%20Screenshot_20200217021548.png)\n\n## Next-key Locks\nNext-key Locks = Gap Locks + index-record lock。\n当在某一个事务中执行一个SELECT语句，Innodb会通过扫描相应的索引记录来找到生成一个ResultSet，这个时候被扫描到的索引记录都被被添加Next-key locks。\n举个例子，假设现在存在一张表T，T的主键为ID，ID的可能值是10，11，13，20。\n现在在一个事务中执行如下语句：\n\n```\nSELECT ID FROM T WHERE ID >=10 AND ID <= 20 FOR UPDATE;\n```\n\n这个时候会产生的Next-key Locks如下:\n\n```\n(-∞, 10]\n(10, 11]\n(11, 13]\n(13, 20]\n(20, +∞)\n```\n其他事务不能这个范围内将不能插入新的纪录（避免了幻读），也不能修改相应的记录（避免了不可重复读）\n\n可见Next-key Locks与Gap Locks主要是为了满足Repeatable read的一致性要求。\n\n另外值得注意的一点是，如果被扫描到的索引是一个唯一索引，且只有并且只有一笔记录，那么这个时候只会上index-record lock，因为这个时候其他事务产生了新的记录，也不会产生幻读。\n\n\n\n\n\n\n"},{"title":"Maven库配置阿里云加速","url":"/2020/01/19/Maven库配置阿里云加速/","content":"\n由于国内的网络原因,通过maven拉取相关package的时候总是特别慢，极大的影响到工作效率。所幸的是阿里云提供了maven库的镜像服务，体验了一下，速度飞快。配置方法如下：\n\n## Maven仓库配置阿里云加速\n- 确定settings.xml配置文件位置\n执行如下命令：\n\n```\nmvn -X\n```\n\n输入如下：\n\n```\n.....省略\n[DEBUG] Reading global settings from /usr/share/maven/conf/settings.xml\n[DEBUG] Reading user settings from /home/abc/.m2/settings.xml\n[DEBUG] Reading global toolchains from /usr/share/maven/conf/toolchains.xml\n[DEBUG] Reading user toolchains from /home/loremipsum/.m2/toolchains.xml\n[DEBUG] Using local repository at /home/abc/.m2/repository\n\n.....省略\n```\n\n- 修改settings.xml,修改mirrors xml结点下的相关配置\n\n```\n  <mirrors>\n    <!-- mirror\n     | Specifies a repository mirror site to use instead of a given repository. The repository that\n     | this mirror serves has an ID that matches the mirrorOf element of this mirror. IDs are used\n     | for inheritance and direct lookup purposes, and must be unique across the set of mirrors.\n     |\n    <mirror>\n      <id>mirrorId</id>\n      <mirrorOf>repositoryId</mirrorOf>\n      <name>Human Readable Name for this Mirror.</name>\n      <url>http://my.repository.com/repo/path</url>\n    </mirror>\n     -->\n    <mirror>\n      <id>aliyun-public</id>\n      <name>aliyun public</name>\n      <mirrorOf>public</mirrorOf>\n      <url>https://maven.aliyun.com/repository/public</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-central</id>\n      <name>aliyun central</name>\n      <mirrorOf>central</mirrorOf>\n      <url>https://maven.aliyun.com/repository/central</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-jcenter</id>\n      <name>aliyun jcenter</name>\n      <mirrorOf>jcenter</mirrorOf>\n      <url>https://maven.aliyun.com/repository/jcenter</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-spring</id>\n      <name>aliyun spring</name>\n      <mirrorOf>spring</mirrorOf>\n      <url>https://maven.aliyun.com/repository/spring</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-spring-milestones</id>\n      <name>aliyun spring milestones</name>\n      <mirrorOf>spring-milestones</mirrorOf>\n      <url>https://maven.aliyun.com/repository/spring</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-spring-plugin</id>\n      <name>aliyun spring plugin</name>\n      <mirrorOf>spring-plugin</mirrorOf>\n      <url>https://maven.aliyun.com/repository/spring-plugin</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-gradle-plugin</id>\n      <name>aliyun gradle plugin</name>\n      <mirrorOf>gradle-plugin</mirrorOf>\n      <url>https://maven.aliyun.com/repository/gradle-plugin</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-google</id>\n      <name>aliyun google</name>\n      <mirrorOf>google</mirrorOf>\n      <url>https://maven.aliyun.com/repository/google</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-grails-core</id>\n      <name>aliyun grails core</name>\n      <mirrorOf>grails-core</mirrorOf>\n      <url>https://maven.aliyun.com/repository/grails-core</url>\n    </mirror>\n</mirrors>\n\n```\n\n## 防坑：\n大部分的包阿里云的maven镜像库都有，一部分比较新的库上面是没有的，如springboot，阿里云上面的版本只是到了2.2.0，实际2.2.4都已经出来了，同步不是很及时。目前我都一些没有的库做了降级处理，后续再看看怎么处理这个问题\n"},{"title":"Kafka连接超时问题的本质","url":"/2020/01/15/Kafka连接超时问题的本质/","content":"## 问题的背景\n前段时间开发环境搭建了一套kafka环境，搭建完成后通过客户端去连接kafka时，当produer调用send的时候程序都会直接hang住，提示连接超时：\n\n```\norg.apache.kafka.common.errors.TimeoutException: \nExpiring 1 record(s) for demo-topic-0:120000 ms has passed since batch creation\n```\n接着我试了一下调用producer的partitionsFor方法，可以正常执行。同样的，当consumer执行poll方法时，程序也会直接卡死。\n\n## 问题的本质\nproducer是通过leader broker往partition写入数据,当producer希望写入数据的时候会向kafka请求当前的leader broker信息，这个时候如果kafka的leader broker的host信息如果和客户端不在同一个网段就会出现上述的超时现象，这也就可以解释为什么partitionsFor方法可以正常执行(不涉及到leader broker的通信)，但是send方法(涉及到leader broker的通信)执行失败。\n\n\n## 问题解决\n\n配置ADVERTISED_HOST\n\n\n```\nbash-4.4# vi $KAFKA_HOME/config/server.properties\n```\n\n这里我的配置是\n\n```\nadvertised.listeners=PLAINTEXT://127.0.0.1:9092\n```\n\n由于是使用docker部署，客户端和服务端不在同一台机器上，所以我需要把这个配置改为与客户端同一个网段的\n\n\n## 问题验证\n\n当ADVERTISED_HOST为PLAINTEXT://127.0.0.1:9092可以看到partitionsFor返回的leader broker信息为下图所示：\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/CD584EBE-9DDF-4bbb-AF15-7970A064979A.png)\n\n修改ADVERTISED_HOST后，返回信息如下：\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/53CA72B0-F276-4ef7-B524-18C970ED3443.png)\n\n\n没有再次出现连接超时的问题\n\n\n## 参考\n[kafka-listeners-explained](https://rmoff.net/2018/08/02/kafka-listeners-explained/)\n\n[Client and broker compatibility across Kafka versions](https://docs.cloudera.com/runtime/7.1.0/kafka-managing/topics/kafka-manage-client-broker-comp.html)"},{"title":"NetCore应用配置Auto Core Dump","url":"/2020/01/09/NetCore应用配置Auto Core Dump/","content":"\n## 问题背景\n前阵子线上用户标签服务频繁出现内存泄漏问题，早上服务运行的好好的，经常一到半夜服务就挂掉。由于事发半夜，很难加以人工干预，而早上dump出来的文件参考价值很低，迫切需要一种自动化的手段让服务在宕掉的时候能够保存完整的案发现场。事实上，.NET CORE可以支持这一需求，不过默认是不开启的，需要加以配置。\n\n## Auto Core Dump配置方法\n\n以下内容是我原封不动从dotnet/rumtime这个仓库拷贝过来的：\n\nEnvironment variables supported:\n\n- `COMPlus_DbgEnableMiniDump`: if set to \"1\", enables this core dump generation. The default is NOT to generate a dump.\n- `COMPlus_DbgMiniDumpType`: See below. Default is \"2\" MiniDumpWithPrivateReadWriteMemory.\n- `COMPlus_DbgMiniDumpName`: if set, use as the template to create the dump path and file name. The pid can be placed in the name with %d. The default is _/tmp/coredump.%d_.\n- `COMPlus_CreateDumpDiagnostics`: if set to \"1\", enables the _createdump_ utilities diagnostic messages (TRACE macro).\n\nCOMPlus_DbgMiniDumpType values:\n\n\n|Value|Minidump Enum|Description|\n|-|:----------:|----------|\n|1| MiniDumpNormal                               | Include just the information necessary to capture stack traces for all existing threads in a process. Limited GC heap memory and information. |\n|2| MiniDumpWithPrivateReadWriteMemory (default) | Includes the GC heaps and information necessary to capture stack traces for all existing threads in a process. |\n|3| MiniDumpFilterTriage                         | Include just the information necessary to capture stack traces for all existing threads in a process. Limited GC heap memory and information. |\n|4| MiniDumpWithFullMemory                       | Include all accessible memory in the process. The raw memory data is included at the end, so that the initial structures can be mapped directly without the raw memory information. This option can result in a very large file. |\n\n\n根据以上内容，可以在Dockerfile或者docker-compose文件加入以下环境变量\n\n```\nENV COMPlus_DbgEnableMiniDump=\"1\"  # enables core dump generation\nENV COMPlus_DbgMiniDumpName=\"/diagnostics/dumps/coredump_%d\" # core dump文件位置，一般是一个挂在在宿主机的目录\nENV COMPlus_DbgMiniDumpType=\"4\" # 建议选择4，也就是full dump，保存的“现场”更加完整，但文件也会非常大\n```\n\n\n## 实验\n\n在一个可以被调用的接口加入以下代码：\n\n```\nEnvironment.FailFast()\n```\n这个方法可以让应用直接挂掉,挂掉后观察相应的挂载目录有无生成dump文件\n\n\n\n## 参考\n\n[xplat-minidump-generation](https://github.com/dotnet/runtime/blob/8497763bbfa70455e6f08ed7aa345d43db1d22d7/docs/design/coreclr/botr/xplat-minidump-generation.md)"}]