[{"title":"高并发场景下StackExchange.Redis驱动的超时问题","url":"/2020/04/23/高并发场景下StackExchange.Redis驱动的超时问题/","content":"## 问题背景\n近期部门的大量微服务在做国际化改造。为了实现国际化需求，需要有一个支撑服务用于提供用户ip信息数据。由于是支撑服务，会产生大量调用，大概每分钟2000次的调用，为了进一步提供性能，该服务会把用户的ip信息缓存到redis以避免重复调用第三方接口获取ip数据。\n上线前对该服务进行了压力测试，发现在高并发的场景下，会频繁发生\n**StackExchange.Redis.RedisTimeoutException**异常，这对于一个支撑服务来说是不可接受的。\n\n## 问题重现\n\n使用grpc压力测试工具[ghz](https://github.com/bojand/ghz)模拟高并发场景：\n\n```\n\tghz 192.168.1.44:43667 --insecure \\\n\t\t--proto ../../proto/FM.Region.Client/Region.proto \\\n\t\t--call Region.RegionSrv/GetRegionInfoDetailByIp \\\n  \t\t--concurrency 400 \\\n\t\t-n 1200 \\\n\t\t-D  ./ip.json\n\n```\n1200请求，400个并发，共3轮测试\n\n测试ip数据集如下：\n\n```\n[\n    {\n        \"IP\": \"27.220.195.252\"\n    },\n    {\n        \"IP\": \"32.213.120.200\"\n    },\n    {\n        \"IP\": \"58.88.5.142\"\n    },\n    {\n        \"IP\": \"99.107.218.202\"\n    },\n    {\n        \"IP\": \"126.179.177.51\"\n    },\n    {\n        \"IP\": \"75.179.58.40\"\n    },\n    {\n        \"IP\": \"92.243.129.145\"\n    },\n    {\n        \"IP\": \"179.240.146.239\"\n    },\n    {\n        \"IP\": \"54.99.209.135\"\n    },\n    {\n        \"IP\": \"116.125.57.197\"\n    },\n    {\n        \"IP\": \"104.243.227.11\"\n    },\n    {\n        \"IP\": \"65.175.113.237\"\n    },\n    {\n        \"IP\": \"92.160.105.28\"\n    },\n    {\n        \"IP\": \"51.189.156.232\"\n    },\n    {\n        \"IP\": \"101.136.19.162\"\n    },\n    {\n        \"IP\": \"128.78.227.70\"\n    },\n    {\n        \"IP\": \"123.139.77.54\"\n    },\n    {\n        \"IP\": \"172.234.209.119\"\n    },\n    {\n        \"IP\": \"187.172.248.233\"\n    },\n    {\n        \"IP\": \"28.8.211.1\"\n    },\n    {\n        \"IP\": \"130.96.236.81\"\n    },\n    {\n        \"IP\": \"88.162.103.72\"\n    },\n    {\n        \"IP\": \"166.2.94.121\"\n    },\n    {\n        \"IP\": \"102.106.115.156\"\n    },\n    {\n        \"IP\": \"19.148.120.200\"\n    },\n    {\n        \"IP\": \"219.240.103.98\"\n    },\n    {\n        \"IP\": \"221.17.125.56\"\n    },\n    {\n        \"IP\": \"91.236.176.82\"\n    },\n    {\n        \"IP\": \"41.237.239.70\"\n    },\n    {\n        \"IP\": \"145.55.30.213\"\n    },\n    {\n        \"IP\": \"139.135.98.132\"\n    },\n    {\n        \"IP\": \"72.143.86.138\"\n    },\n    {\n        \"IP\": \"198.225.10.195\"\n    },\n    {\n        \"IP\": \"136.234.70.30\"\n    },\n    {\n        \"IP\": \"103.89.118.202\"\n    },\n    {\n        \"IP\": \"44.250.218.13\"\n    },\n    {\n        \"IP\": \"116.207.166.76\"\n    },\n    {\n        \"IP\": \"140.238.239.80\"\n    },\n    {\n        \"IP\": \"31.158.163.164\"\n    },\n    {\n        \"IP\": \"182.215.64.241\"\n    },\n    {\n        \"IP\": \"220.197.147.157\"\n    },\n    {\n        \"IP\": \"117.254.129.148\"\n    },\n    {\n        \"IP\": \"94.184.10.88\"\n    },\n    {\n        \"IP\": \"219.61.223.175\"\n    },\n    {\n        \"IP\": \"185.172.199.161\"\n    },\n    {\n        \"IP\": \"184.69.18.249\"\n    },\n    {\n        \"IP\": \"166.64.229.72\"\n    },\n    {\n        \"IP\": \"212.98.0.204\"\n    },\n    {\n        \"IP\": \"160.59.24.87\"\n    },\n    {\n        \"IP\": \"48.195.150.66\"\n    },\n    {\n        \"IP\": \"147.186.60.20\"\n    },\n    {\n        \"IP\": \"138.19.147.96\"\n    },\n    {\n        \"IP\": \"8.43.149.29\"\n    },\n    {\n        \"IP\": \"108.94.149.179\"\n    },\n    {\n        \"IP\": \"111.177.253.182\"\n    },\n    {\n        \"IP\": \"99.160.130.179\"\n    },\n    {\n        \"IP\": \"125.194.19.83\"\n    },\n    {\n        \"IP\": \"26.100.156.127\"\n    },\n    {\n        \"IP\": \"105.18.80.126\"\n    },\n    {\n        \"IP\": \"128.141.4.89\"\n    },\n    {\n        \"IP\": \"80.20.225.251\"\n    },\n    {\n        \"IP\": \"41.253.214.98\"\n    },\n    {\n        \"IP\": \"36.5.58.33\"\n    },\n    {\n        \"IP\": \"56.52.122.254\"\n    },\n    {\n        \"IP\": \"162.240.161.83\"\n    },\n    {\n        \"IP\": \"195.221.65.187\"\n    },\n    {\n        \"IP\": \"223.215.140.121\"\n    },\n    {\n        \"IP\": \"42.254.253.187\"\n    },\n    {\n        \"IP\": \"99.236.88.173\"\n    },\n    {\n        \"IP\": \"87.49.237.85\"\n    },\n    {\n        \"IP\": \"124.230.221.226\"\n    },\n    {\n        \"IP\": \"46.22.123.116\"\n    },\n    {\n        \"IP\": \"105.85.140.56\"\n    },\n    {\n        \"IP\": \"69.167.167.233\"\n    },\n    {\n        \"IP\": \"176.44.47.123\"\n    },\n    {\n        \"IP\": \"40.225.1.63\"\n    },\n    {\n        \"IP\": \"102.209.225.101\"\n    },\n    {\n        \"IP\": \"62.173.169.38\"\n    },\n    {\n        \"IP\": \"51.133.22.72\"\n    },\n    {\n        \"IP\": \"31.129.69.30\"\n    },\n    {\n        \"IP\": \"194.133.28.78\"\n    },\n    {\n        \"IP\": \"9.243.223.78\"\n    },\n    {\n        \"IP\": \"185.107.13.97\"\n    },\n    {\n        \"IP\": \"155.131.137.219\"\n    }\n]\n```\n\n测试输出：\n\n```\n\n\n\nSummary:\n  Count:        1200\n  Total:        36.67 s\n  Slowest:      19.65 s\n  Fastest:      1.01 s\n  Average:      11.12 s\n  Requests/sec: 32.72\n\nResponse time histogram:\n  1011.354 [1]  |\n  2875.261 [8]  |∎\n  4739.167 [13] |∎\n  6603.074 [17] |∎∎\n  8466.981 [230]        |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  10330.887 [117]       |∎∎∎∎∎∎∎∎∎∎∎\n  12194.794 [440]       |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  14058.701 [172]       |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  15922.608 [145]       |∎∎∎∎∎∎∎∎∎∎∎∎∎\n  17786.514 [44]        |∎∎∎∎\n  19650.421 [7] |∎\n\nLatency distribution:\n  10%% in 8.15 s\n  25%% in 9.21 s\n  50%% in 11.17 s\n  75%% in 12.50 s\n  90%% in 14.51 s\n  95%% in 15.28 s\n  99%% in 17.24 s\n\nStatus code distribution:\n  [OK]                 1194 responses\n  [DeadlineExceeded]   6 responses\n\nError distribution:\n  [5]   rpc error: code = DeadlineExceeded desc = context deadline exceeded\n  [1]   rpc error: code = DeadlineExceeded desc = Deadline Exceeded\n```\n测试输出提示请求超时，而且大量请求响应时间很不理想，查看日志发现StackExchange.Redis.RedisTimeoutException异常：\n\n\n```\nStackExchange.Redis.RedisTimeoutException: Timeout performing EVAL, inst: 5, queue: 1032, qu: 0, qs: 1032, qc: 0, wr: 0, wq: 0, in: 97489, ar: 0, clientName: , serverEndpoint: 192.168.1.44:43667, keyHashSlot: 693 (Please take a look at this article for some common client-side issues that can cause timeouts: http:\\/\\/stackexchange.github.io\\/StackExchange.Redis\\/Timeouts)\\n   at StackExchange.Redis.ConnectionMultiplexer.ExecuteSyncImpl[T](Message message, ResultProcessor`1 processor, ServerEndPoint server ...\n```\n## 问题解决\n根据[StackExchange.Redis官方文档](https://github.com/StackExchange/StackExchange.Redis/blob/master/docs/Timeouts.md)描述,在高并发场景下，当StackExchange.Redis的内部线程池无法满足并发要求的时候会去请求CLR的全局线程池，全局线程池的初始线程数量是根据CPU的核心数来确定的，当全局线程池的线程不够用的时候，会以500ms/per thread的速度往线程池里面添加新的线程，但这个速度在高并发场景下还是远远不够的，为此需要配置CLR线程池的最小线程数来满足高并发的场景。\n在程序入口添加如下代码：\n\n```\nThreadPool.SetMinThreads(512, 100) //worker最小线程数512,IOCP最小线程数100\n```\n\n\n## 问题验证\n配置最小线程数后再进行压力测试，测试输出如下：\n\n```\nSummary:\n  Count:        1200\n  Total:        2.66 s\n  Slowest:      2.15 s\n  Fastest:      1.99 ms\n  Average:      827.12 ms\n  Requests/sec: 451.92\n\nResponse time histogram:\n  1.987 [1]     |\n  216.449 [66]  |∎∎∎∎∎∎∎\n  430.911 [174] |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  645.373 [403] |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  859.835 [136] |∎∎∎∎∎∎∎∎∎∎∎∎∎\n  1074.297 [75] |∎∎∎∎∎∎∎\n  1288.759 [48] |∎∎∎∎∎\n  1503.221 [69] |∎∎∎∎∎∎∎\n  1717.683 [156]        |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  1932.145 [13] |∎\n  2146.607 [59] |∎∎∎∎∎∎\n\nLatency distribution:\n  10%% in 332.77 ms\n  25%% in 445.91 ms\n  50%% in 547.70 ms\n  75%% in 1.28 s\n  90%% in 1.68 s\n  95%% in 1.91 s\n  99%% in 2.11 s\n\nStatus code distribution:\n  [OK]   1200 responses\n\n```\n超时问题消失,并且响应时间大幅度减小\n\n\n需要注意的是，如果机器配置不够（CPU跑满了)，再高并发场景下，仍然会出现超时问题。\n\n\n"},{"title":"NetCore应用配置Auto Core Dump","url":"/2020/04/13/NetCore应用配置Auto Core Dump/","content":"\n## 问题背景\n前阵子线上用户标签服务频繁出现内存泄漏问题，早上服务运行的好好的，经常一到半夜服务就挂掉。由于事发半夜，很难加以人工干预，而早上dump出来的文件参考价值很低，迫切需要一种自动化的手段让服务在宕掉的时候能够保存完整的案发现场。事实上，.NET CORE可以支持这一需求，不过默认是不开启的，需要加以配置。\n\n## Auto Core Dump配置方法\n\n以下内容是我原封不动从dotnet/rumtime这个仓库拷贝过来的：\n\nEnvironment variables supported:\n\n- `COMPlus_DbgEnableMiniDump`: if set to \"1\", enables this core dump generation. The default is NOT to generate a dump.\n- `COMPlus_DbgMiniDumpType`: See below. Default is \"2\" MiniDumpWithPrivateReadWriteMemory.\n- `COMPlus_DbgMiniDumpName`: if set, use as the template to create the dump path and file name. The pid can be placed in the name with %d. The default is _/tmp/coredump.%d_.\n- `COMPlus_CreateDumpDiagnostics`: if set to \"1\", enables the _createdump_ utilities diagnostic messages (TRACE macro).\n\nCOMPlus_DbgMiniDumpType values:\n\n\n|Value|Minidump Enum|Description|\n|-|:----------:|----------|\n|1| MiniDumpNormal                               | Include just the information necessary to capture stack traces for all existing threads in a process. Limited GC heap memory and information. |\n|2| MiniDumpWithPrivateReadWriteMemory (default) | Includes the GC heaps and information necessary to capture stack traces for all existing threads in a process. |\n|3| MiniDumpFilterTriage                         | Include just the information necessary to capture stack traces for all existing threads in a process. Limited GC heap memory and information. |\n|4| MiniDumpWithFullMemory                       | Include all accessible memory in the process. The raw memory data is included at the end, so that the initial structures can be mapped directly without the raw memory information. This option can result in a very large file. |\n\n\n根据以上内容，可以在Dockerfile或者docker-compose文件加入以下环境变量\n\n```\nENV COMPlus_DbgEnableMiniDump=\"1\"  # enables core dump generation\nENV COMPlus_DbgMiniDumpName=\"/diagnostics/dumps/coredump_%d\" # core dump文件位置，一般是一个挂在在宿主机的目录\nENV COMPlus_DbgMiniDumpType=\"4\" # 建议选择4，也就是full dump，保存的“现场”更加完整，但文件也会非常大\n```\n\n\n## 实验\n\n在一个可以被调用的接口加入以下代码：\n\n```\nEnvironment.FailFast()\n```\n这个方法可以让应用直接挂掉,挂掉后观察相应的挂载目录有无生成dump文件\n\n\n\n## 参考\n\n[xplat-minidump-generation](https://github.com/dotnet/runtime/blob/8497763bbfa70455e6f08ed7aa345d43db1d22d7/docs/design/coreclr/botr/xplat-minidump-generation.md)"},{"title":"记线上的一次Mysql死锁问题分析","url":"/2020/04/12/记线上的一次Mysql死锁问题分析/","content":"\n## 问题描述\n最近上线了叫做“F币”的功能，简单说下就是系统会根据用户每天在社区的活跃行为，计算每一个用户的活跃度，最后根据用户每天的总活跃度返还相应的“F币”给用户，用户得到F币之后可以在社区兑换不同的礼品,如下图所示：\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/BF0B1ABB-F459-4343-BE90-5177FB6583D5.png)\n\n在测试环境和仿真环境运行的好好的，但是上线之后经常接到用户反馈，需要多次点击才能完成领取。查看阿里云日志，提示数据库产生死锁，如下图所示：\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/9DF85AF7-0840-4323-9B0C-613480533A45.png)\n\n## 问题分析\n注意到这里有一排按钮，用户的每次点击，后台都会进行以下两个操作：\n1. 更新用户余额（用户表）\n2. 生成流水记录 （用户流水记录）\n\n注：用户表和流水表存在主外键关系\n\n以上的两个操作会放在同一个事务完成，并且由于Ef的SaveChanges并不会根据你代码执行的先后次序去更新数据库，当用户以很快的速度从左到右依次点击，存在以下可能：\n\nT1:事务A插入流水，由于存在外键，会对user对应的行上S锁。\n\nT2:事务B插入流水，由于存在外键，会对user对应的行上S锁。\n\nT3:事务A更新User的余额，请求行记录的X锁，被B事务在T2的S锁阻塞\n\nT4:事务B更新User的余额，请求行记录的X锁，被A事务在T1的S锁阻塞\n\n至此死锁产生。\n\n\n\n## 问题解决\n\n用了一个比较简单+暴力的方法：领取接口直接上redis分布式锁。\n\n\n## 总结与反思\n\n这个项目是使用DDD的思想进行开发的，自然而然地在ORM上面的选型使用了EntityFramework Code First,但是Code Firit在建表的时候会自做主张的在“多”端生成外键。对外键的使用，除开了一部分性能开销，就是上述的死锁问题，后续考虑把这部分重构为DbFirst。\n\n另外值得一提的是，后来对这部逻辑做了压测，发现这部分代码在Sql Server跑是没问题的，因为Sql Server在插入子表的时候不会对父表记录上锁，而Mysql会对父表上锁,所以产生了死锁，天下果然没有免费午餐！\n\n\n\n## 参考\n\n\n[DbContext SaveChanges Order of Statement Execution\n](https://stackoverflow.com/questions/7335582/dbcontext-savechanges-order-of-statement-execution)\n\n[Deadlock due to Foreign Key constraint](https://bugs.mysql.com/bug.php?id=48652)"},{"title":"AspNetCore2.1升级到3.1时CORS相关配置的变更","url":"/2020/02/19/AspNetCore2.1升级到3.1时CORS相关配置的变更/","content":"\n本周将公司的运营系统从AspNetCore2.1升级到了AspNetCore3.1,遇到了一些坑，这里记录以下\n\n## 2.1的相关CORS代码\n\n\n```\npublic IServiceProvider ConfigureServices(IServiceCollection services)\n{\n\n        ... // 省略\n        services.AddCors(option => option.AddPolicy(\"corsPolicy\", builders =>\n        {\n            builders.AllowCredentials().AllowAnyOrigin().AllowAnyHeader().AllowAnyMethod();\n        }));\n        ... // 省略\n}\n\npublic void Configure(IApplicationBuilder app, ILoggerFactory loggerFactory, IHostingEnvironment env)\n{\n    ... // 省略\n    app.UseCors(\"corsPolicy\");\n     ... // 省略\n}\n```\n\n如果这部分代码这3.1的服务中不加任何修改，启动时提示错误：\n\n\n```\nThe CORS protocol does not allow specifying a wildcard (any) origin and credentials at the same time. Configure the CORS policy by listing individual origins if credentials needs to be supported.\n```\n\n\n这是由于在2.1之后,AspNetCore出于安全考虑，做了更加严格的限制，在不AllowCredentials()与AllowAnyOrigin()。\n\n假设现在站点A存在一个恶意脚本，而站点B存在一个比较的敏感的接口（如转账）。如果站点B作为服务端使用AllowCredentials()与AllowAnyOrigin()的同源配置，此时站点A可以直接调用站点B的敏感接口并发送凭证信息（如Cookie），那么将导致用户信息被窃取。\n\n\n\n## 3.1的相关CORS代码\n\n### options1 显示声明允许跨域的origin\n\n```\nservices.AddCors(option => option.AddPolicy(\"corsPolicy\", builders =>\n            {\n                builders.WithOrigins(\"http://site.com\").AllowAnyHeader().AllowAnyMethod().AllowCredentials();\n            }));\n```\n\n\n### options2 使用 SetIsOriginAllowed（可以起到与AllowAnyOriginu一样的效果）\n\n\n```\nservices.AddCors(option => option.AddPolicy(\"corsPolicy\", builders =>\n            {\n                builders.SetIsOriginAllowed(origin=>true).AllowAnyHeader().AllowAnyMethod().AllowCredentials(); //SetIsOriginAllowed(origin=>true)允许所有origin\n            }));\n```\n\n\n"},{"title":"Maven库配置阿里云加速","url":"/2020/02/17/Maven库配置阿里云加速/","content":"\n由于国内的网络原因,通过maven拉取相关package的时候总是特别慢，极大的影响到工作效率。所幸的是阿里云提供了maven库的镜像服务，体验了一下，速度飞快。配置方法如下：\n\n## Maven仓库配置阿里云加速\n- 确定settings.xml配置文件位置\n执行如下命令：\n\n```\nmvn -X\n```\n\n输入如下：\n\n```\n.....省略\n[DEBUG] Reading global settings from /usr/share/maven/conf/settings.xml\n[DEBUG] Reading user settings from /home/abc/.m2/settings.xml\n[DEBUG] Reading global toolchains from /usr/share/maven/conf/toolchains.xml\n[DEBUG] Reading user toolchains from /home/loremipsum/.m2/toolchains.xml\n[DEBUG] Using local repository at /home/abc/.m2/repository\n\n.....省略\n```\n\n- 修改settings.xml,修改mirrors xml结点下的相关配置\n\n```\n  <mirrors>\n    <!-- mirror\n     | Specifies a repository mirror site to use instead of a given repository. The repository that\n     | this mirror serves has an ID that matches the mirrorOf element of this mirror. IDs are used\n     | for inheritance and direct lookup purposes, and must be unique across the set of mirrors.\n     |\n    <mirror>\n      <id>mirrorId</id>\n      <mirrorOf>repositoryId</mirrorOf>\n      <name>Human Readable Name for this Mirror.</name>\n      <url>http://my.repository.com/repo/path</url>\n    </mirror>\n     -->\n    <mirror>\n      <id>aliyun-public</id>\n      <name>aliyun public</name>\n      <mirrorOf>public</mirrorOf>\n      <url>https://maven.aliyun.com/repository/public</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-central</id>\n      <name>aliyun central</name>\n      <mirrorOf>central</mirrorOf>\n      <url>https://maven.aliyun.com/repository/central</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-jcenter</id>\n      <name>aliyun jcenter</name>\n      <mirrorOf>jcenter</mirrorOf>\n      <url>https://maven.aliyun.com/repository/jcenter</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-spring</id>\n      <name>aliyun spring</name>\n      <mirrorOf>spring</mirrorOf>\n      <url>https://maven.aliyun.com/repository/spring</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-spring-milestones</id>\n      <name>aliyun spring milestones</name>\n      <mirrorOf>spring-milestones</mirrorOf>\n      <url>https://maven.aliyun.com/repository/spring</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-spring-plugin</id>\n      <name>aliyun spring plugin</name>\n      <mirrorOf>spring-plugin</mirrorOf>\n      <url>https://maven.aliyun.com/repository/spring-plugin</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-gradle-plugin</id>\n      <name>aliyun gradle plugin</name>\n      <mirrorOf>gradle-plugin</mirrorOf>\n      <url>https://maven.aliyun.com/repository/gradle-plugin</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-google</id>\n      <name>aliyun google</name>\n      <mirrorOf>google</mirrorOf>\n      <url>https://maven.aliyun.com/repository/google</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-grails-core</id>\n      <name>aliyun grails core</name>\n      <mirrorOf>grails-core</mirrorOf>\n      <url>https://maven.aliyun.com/repository/grails-core</url>\n    </mirror>\n</mirrors>\n\n```\n\n## 防坑：\n大部分的包阿里云的maven镜像库都有，一部分比较新的库上面是没有的，如springboot，阿里云上面的版本只是到了2.2.0，实际2.2.4都已经出来了，同步不是很及时。目前我都一些没有的库做了降级处理，后续再看看怎么处理这个问题\n"},{"title":"InnodDB中的Gap Locks与Next-key Locks","url":"/2020/02/17/InnodDB中的Gap Locks与Next-key Locks/","content":"\n为了理解Gap Locks与Next-key Locks首先必须了解InnodDB定义的四种隔离级别\n\n## InnodDB的四种隔离级别\n\n1. Read uncommitted(未授权读取、读未提交)：如果一个事务已经开始写数据，则另外一个事务则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。这样就避免了更新丢失，却可能出现脏读。也就是说事务B读取到了事务A未提交的数据。\n2. Read committed（授权读取、读提交）： 读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。该隔离级别避免了脏读，但是却可能出现不可重复读。事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。\n3. Repeatable read（可重复读取,MySQL默认隔离级别）： 可重复读是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，即使第二个事务对数据进行修改，第一个事务两次读到的的数据是一样的。这样就发生了在一个事务内两次读到的数据是一样的，因此称为是可重复读。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。这样避免了不可重复读取和脏读，但是有时可能出现幻象读。（读取数据的事务）这可以通过“共享读锁”和“排他写锁”实现。\n4. Serializable（序列化）： 提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。序列化是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。 \n\n\n## Gap Locks\n如下图所示：假设存在一个索引(Key,pk),那么当innodb在一事务中中对(-∞,(9,5)]追加Gap Locks后,如果其他事务尝试在索引记录中的任意一个Gap添加记录,该事务将会被阻塞\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/WeChat%20Screenshot_20200217021548.png)\n\n## Next-key Locks\nNext-key Locks = Gap Locks + index-record lock。\n当在某一个事务中执行一个SELECT语句，Innodb会通过扫描相应的索引记录来找到生成一个ResultSet，这个时候被扫描到的索引记录都被被添加Next-key locks。\n举个例子，假设现在存在一张表T，T的主键为ID，ID的可能值是10，11，13，20。\n现在在一个事务中执行如下语句：\n\n```\nSELECT ID FROM T WHERE ID >=10 AND ID <= 20 FOR UPDATE;\n```\n\n这个时候会产生的Next-key Locks如下:\n\n```\n(-∞, 10]\n(10, 11]\n(11, 13]\n(13, 20]\n(20, +∞)\n```\n其他事务不能这个范围内将不能插入新的纪录（避免了幻读），也不能修改相应的记录（避免了不可重复读）\n\n可见Next-key Locks与Gap Locks主要是为了满足Repeatable read的一致性要求。\n\n另外值得注意的一点是，如果被扫描到的索引是一个唯一索引，且只有并且只有一笔记录，那么这个时候只会上index-record lock，因为这个时候其他事务产生了新的记录，也不会产生幻读。\n\n\n\n\n\n\n"}]