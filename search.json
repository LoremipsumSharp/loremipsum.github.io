[{"title":"Spring Data MongoDb 通过Gradle集成QureyDSL的配置方法","url":"/2020/05/17/Spring Data MongoDb 通过Gradle集成QureyDSL的配置方法/","content":"\n## 引言\nQueryDSL是一个通用的查询框架，专注于通过Java API构建类型安全的SQL查询。目前在 Github 上的发布的 Release 版本已经多达 251 个版本，目前最新版是 4.3.1 ，并且由 Querydsl Google组 和 StackOverflow 两个团队提供支持。QueryDSL 是一个框架，可用于构造静态类型的类似SQL的查询。可以通过诸如 QueryDSL 之类的 API 构造查询，而不是将查询编写为内联字符串或将其外部化为XML文件。\n\n例如，与简单字符串相比，使用 API 的好处是\n\n- IDE中的代码完成\n\n- 几乎没有语法无效的查询\n\n- 可以安全地引用域类型和属性\n\n- 更好地重构域类型的更改\n\n\n目前网上能够查阅到通过gradle集成QueryDSL的资料非常少，大部分是基于Maven，基于gradle的配置方法很多都是错的（这个是由于gradle的版本升级，新版本的gradle对QueryDSL没有做到向下兼容）\n\n\n## gradle配置方法\n\n\n\n```\nplugins {\n    id 'org.springframework.boot' version '2.2.5.RELEASE'\n    id 'io.spring.dependency-management' version '1.0.9.RELEASE'\n    id 'java'\n    id \"com.ewerk.gradle.plugins.querydsl\" version \"1.0.10\"\n\n}\n\ngroup = 'io.loremipsum'\nversion = '0.0.1-SNAPSHOT'\nsourceCompatibility = '11'\n\n\nrepositories {\n    mavenCentral()\n}\n\n\nquerydsl {\n    library = 'com.querydsl:querydsl-apt:4.1.4'\n    querydslSourcesDir = 'src/main/querydsl'\n    springDataMongo = true\n}\n\nsourceSets {\n    main {\n        java {\n            srcDirs = ['src/main/java', 'src/main/querydsl']\n        }\n    }\n}\n\n// 当gradle版本>5.0的时候需要加上这个配置\ncompileQuerydsl {\n    options.annotationProcessorPath = configurations.querydsl\n}\n\ndependencies {\n    compile 'org.springframework.boot:spring-boot-starter-data-mongodb'\n    compile 'org.springframework.boot:spring-boot-starter-web'\n\n    compile(\"com.querydsl:querydsl-core:4.1.4\")\n    compile(\"com.querydsl:querydsl-mongodb:4.1.4\")\n    compile(\"com.querydsl:querydsl-apt:4.1.4\")\n\n    compile 'org.projectlombok:lombok'\n    annotationProcessor 'org.projectlombok:lombok'\n\n    testCompile('org.springframework.boot:spring-boot-starter-test')\n    testCompile 'de.flapdoodle.embed:de.flapdoodle.embed.mongo'\n}\n```\n\n注意上述配置mongodb的依赖必须声明为compile（如果通过spring boot initializer创建项目,这里会被声明为implementation)，否则会提示：\n\n```\nAnnotation processor 'org.springframework.data.mongodb.repository.support.MongoAnnotationProcessor' not found\n```\n\n\n\n\n\n## 参考\n\n[Spring Boot （六）： 为 JPA 插上翅膀的 QueryDSL](https://www.cnblogs.com/babycomeon/p/11605809.html)\n\n[Querydsl Annotation Processor issue after upgrade to Gradle 5](https://stackoverflow.com/questions/53913274/querydsl-annotation-processor-issue-after-upgrade-to-gradle-5)\n\n[querydsl-plugin don't work in Gradle 5.0](https://github.com/ewerk/gradle-plugins/issues/108)"},{"title":"使用ValueTask减少假异步代码引起的GC","url":"/2020/04/27/使用ValueTask减少假异步代码引起的GC/","content":"## async/await代码存在的问题\nasync/await是.NET4.5引入的一个语法糖，如下所示，下面的代码首先会以同步的方法判断一个文件是否存在，如果存在，那么就会已异步的方式去读取文件的内容：\n\n```\npublic async Task<string> ReadFileAsync(string filename)\n{\n    if (!File.Exists(filename))\n        return string.Empty;\n    return await File.ReadAllTextAsync(filename);\n}\n```\n通过async/await开发人员可以编写更加简洁的异步代码，通过IL SPY我们可以观察到，编译器实际上将async/await转为为了一个StateMachine,如下所示：\n\n```\n[AsyncStateMachine(typeof(Program.<ReadFileAsync>d__14))]\npublic Task<string> ReadFileAsync(string filename)\n{\n    Program.<ReadFileAsync>d__14 <ReadFileAsync>d__;\n    <ReadFileAsync>d__.filename = filename;\n    <ReadFileAsync>d__.<>t__builder = AsyncTaskMethodBuilder<string>.\n    Create();\n    <ReadFileAsync>d__.<>1__state = -1;\n    AsyncTaskMethodBuilder<string> <>t__builder = <ReadFileAsync>d__.<>t__\n    builder;\n    <>t__builder.Start<Program.<ReadFileAsync>d__14>(ref <ReadFileAsync>d__);\n    return <ReadFileAsync>d__.<>t__builder.Task;\n}\n[CompilerGenerated]\n[StructLayout(LayoutKind.Auto)]\nprivate struct <ReadFileAsync>d__14 : IAsyncStateMachine\n{\n    void IAsyncStateMachine.MoveNext()\n    {\n        int num = this.<>1__state;\n        string result;\n        try\n        {\n            TaskAwaiter<string> awaiter;\n            if (num != 0)\n            {\n                if (!File.Exists(this.filename))\n                {\n                    result = string.Empty;\n                    goto IL_A4;\n                }\n                awaiter = File.ReadAllTextAsync(this.filename,\n                default(CancellationToken)).GetAwaiter();\n                if (!awaiter.get_IsCompleted())\n                {\n                    this.<>1__state = 0;\n                    this.<>u__1 = awaiter;\n                    this.<>t__builder.AwaitUnsafeOnCompleted<TaskAwaiter\n                    <string>, Program.<ReadFileAsync>d__14>(ref awaiter, ref\n                    this);\n                    return;\n                }\n        }\n        else\n        {\n            awaiter = this.<>u__1;\n            this.<>u__1 = default(TaskAwaiter<string>);\n            this.<>1__state = -1;\n        }   \n        result = awaiter.GetResult();\n    }\n    catch (Exception exception)\n    {\n        this.<>1__state = -2;\n        this.<>t__builder.SetException(exception);\n        return;\n    }\n\n    IL_A4:\n    this.<>1__state = -2;\n    this.<>t__builder.SetResult(result);\n    }\n}\n```\n\n注意到上面的代码，当文件不存在的时候会执行goto语句，也就是this.<>t__builder.SetResult(result)，t_builder是AsyncTaskMethodBuilder<T>的一个实例，\n我们可以看下SetResult的[实现](https://github.com/dotnet/runtime/blob/110282c71b3f7e1f91ea339953f4a0eba362a62c/src/libraries/System.Private.CoreLib/src/System/Runtime/CompilerServices/AsyncTaskMethodBuilderT.cs)\n\n```\npublic void SetResult(TResult result)\n{\n    // Get the currently stored task, which will be non-null if get_Task has already been accessed.\n    // If there isn't one, get a task and store it.\n    if (m_task is null)\n    {\n        m_task = GetTaskForResult(result);\n        Debug.Assert(m_task != null, $\"{nameof(GetTaskForResult)} should never return null\");\n    }\n    else\n    {\n        // Slow path: complete the existing task.\n        SetExistingTaskResult(m_task, result);\n    }\n}\n```\n由于此时这个时候并产生真正的异步操作，所以m_task is null 成立,查看GetTaskForResult(result)：\n\n```\n[MethodImpl(MethodImplOptions.AggressiveInlining)] \n// method looks long, but for a given TResult it results in a relatively small amount of asm\ninternal static Task<TResult> GetTaskForResult(TResult result)\n{\n    if (null != (object?)default(TResult)) // help the JIT avoid the value type branches for ref types\n    {\n        .....\n    }\n    else if (result == null) // optimized away for value types\n    {\n        return s_defaultResultTask;\n    }\n    return new Task<TResult>(result);\n    }\n}\n```\n由于string是引用类型且result不为null,所以必然会导致一个新的Task对象被创建，那么也就是说，即便不存在异步调用，也会创建一个新的Task对象，如果存在大量的假异步调用，势必会造成成大量的一代GC，从而影响程序的性能。\n\n## 问题的解决\n为了解决上述问题，.NET CORE 2.1引入了一个新的概念，ValueTask：\n\n```\npublic struct ValueTask<TResult>\n{\n\n    IValueTaskSource<TResult>\n    internal readonly object _obj;\n    internal readonly TResult _result;\n}\n```\n\n使用ValueTask改写ReadFile代码：\n\n```\npublic async ValueTask<string> ReadFileAsync(string filename)\n{\n    if (!File.Exists(filename))\n        return string.Empty;\n    return await File.ReadAllTextAsync(filename);\n}\n```\n当调用ReadFileAsync时，可以使用ValueTask.IsCompleted来判断这个调用是不是假异步调用，如下所示：\n\n```\nvar valueTask = ReadFileAsync();\nif(valueTask.IsCompleted)\n{\n    return valueTask.Result;\n}\nelse\n{\n    return await valueTask.AsTask();\n}\n```\n如果假异步调用，IsCompleted为true，这个时候返回valueTask.Result,不会产生Task对象的分配而ValueTask本身也是一个值类型，也不会产生allocation。反之，如果是真异步调用则按照原来的逻辑去执行。\n\n\n## 结论\n当应用程序对性能要求比较苛刻的时候并且存在大量假异步调用的情况下，可以考虑使用ValueTask来提高性能。"},{"title":"高并发场景下StackExchange.Redis驱动的超时问题","url":"/2020/04/25/高并发场景下StackExchange.Redis驱动的超时问题/","content":"## 问题背景\n近期部门的大量微服务在做国际化改造。为了实现国际化需求，需要有一个支撑服务用于提供用户ip信息数据。由于是支撑服务，会产生大量调用，大概每分钟2000次的调用，为了进一步提供性能，该服务会把用户的ip信息缓存到redis以避免重复调用第三方接口获取ip数据。\n上线前对该服务进行了压力测试，发现在高并发的场景下，会频繁发生\n**StackExchange.Redis.RedisTimeoutException**异常，这对于一个支撑服务来说是不可接受的。\n\n## 问题重现\n\n使用grpc压力测试工具[ghz](https://github.com/bojand/ghz)模拟高并发场景：\n\n```\n\tghz 192.168.1.44:43667 --insecure \\\n\t\t--proto ../../proto/FM.Region.Client/Region.proto \\\n\t\t--call Region.RegionSrv/GetRegionInfoDetailByIp \\\n  \t\t--concurrency 400 \\\n\t\t-n 1200 \\\n\t\t-D  ./ip.json\n\n```\n1200请求，400个并发，共3轮测试\n\n测试ip数据集如下：\n\n```\n[\n    {\n        \"IP\": \"27.220.195.252\"\n    },\n    {\n        \"IP\": \"32.213.120.200\"\n    },\n    {\n        \"IP\": \"58.88.5.142\"\n    },\n    {\n        \"IP\": \"99.107.218.202\"\n    },\n    {\n        \"IP\": \"126.179.177.51\"\n    },\n    {\n        \"IP\": \"75.179.58.40\"\n    },\n    {\n        \"IP\": \"92.243.129.145\"\n    },\n    {\n        \"IP\": \"179.240.146.239\"\n    },\n    {\n        \"IP\": \"54.99.209.135\"\n    },\n    {\n        \"IP\": \"116.125.57.197\"\n    },\n    {\n        \"IP\": \"104.243.227.11\"\n    },\n    {\n        \"IP\": \"65.175.113.237\"\n    },\n    {\n        \"IP\": \"92.160.105.28\"\n    },\n    {\n        \"IP\": \"51.189.156.232\"\n    },\n    {\n        \"IP\": \"101.136.19.162\"\n    },\n    {\n        \"IP\": \"128.78.227.70\"\n    },\n    {\n        \"IP\": \"123.139.77.54\"\n    },\n    {\n        \"IP\": \"172.234.209.119\"\n    },\n    {\n        \"IP\": \"187.172.248.233\"\n    },\n    {\n        \"IP\": \"28.8.211.1\"\n    },\n    {\n        \"IP\": \"130.96.236.81\"\n    },\n    {\n        \"IP\": \"88.162.103.72\"\n    },\n    {\n        \"IP\": \"166.2.94.121\"\n    },\n    {\n        \"IP\": \"102.106.115.156\"\n    },\n    {\n        \"IP\": \"19.148.120.200\"\n    },\n    {\n        \"IP\": \"219.240.103.98\"\n    },\n    {\n        \"IP\": \"221.17.125.56\"\n    },\n    {\n        \"IP\": \"91.236.176.82\"\n    },\n    {\n        \"IP\": \"41.237.239.70\"\n    },\n    {\n        \"IP\": \"145.55.30.213\"\n    },\n    {\n        \"IP\": \"139.135.98.132\"\n    },\n    {\n        \"IP\": \"72.143.86.138\"\n    },\n    {\n        \"IP\": \"198.225.10.195\"\n    },\n    {\n        \"IP\": \"136.234.70.30\"\n    },\n    {\n        \"IP\": \"103.89.118.202\"\n    },\n    {\n        \"IP\": \"44.250.218.13\"\n    },\n    {\n        \"IP\": \"116.207.166.76\"\n    },\n    {\n        \"IP\": \"140.238.239.80\"\n    },\n    {\n        \"IP\": \"31.158.163.164\"\n    },\n    {\n        \"IP\": \"182.215.64.241\"\n    },\n    {\n        \"IP\": \"220.197.147.157\"\n    },\n    {\n        \"IP\": \"117.254.129.148\"\n    },\n    {\n        \"IP\": \"94.184.10.88\"\n    },\n    {\n        \"IP\": \"219.61.223.175\"\n    },\n    {\n        \"IP\": \"185.172.199.161\"\n    },\n    {\n        \"IP\": \"184.69.18.249\"\n    },\n    {\n        \"IP\": \"166.64.229.72\"\n    },\n    {\n        \"IP\": \"212.98.0.204\"\n    },\n    {\n        \"IP\": \"160.59.24.87\"\n    },\n    {\n        \"IP\": \"48.195.150.66\"\n    },\n    {\n        \"IP\": \"147.186.60.20\"\n    },\n    {\n        \"IP\": \"138.19.147.96\"\n    },\n    {\n        \"IP\": \"8.43.149.29\"\n    },\n    {\n        \"IP\": \"108.94.149.179\"\n    },\n    {\n        \"IP\": \"111.177.253.182\"\n    },\n    {\n        \"IP\": \"99.160.130.179\"\n    },\n    {\n        \"IP\": \"125.194.19.83\"\n    },\n    {\n        \"IP\": \"26.100.156.127\"\n    },\n    {\n        \"IP\": \"105.18.80.126\"\n    },\n    {\n        \"IP\": \"128.141.4.89\"\n    },\n    {\n        \"IP\": \"80.20.225.251\"\n    },\n    {\n        \"IP\": \"41.253.214.98\"\n    },\n    {\n        \"IP\": \"36.5.58.33\"\n    },\n    {\n        \"IP\": \"56.52.122.254\"\n    },\n    {\n        \"IP\": \"162.240.161.83\"\n    },\n    {\n        \"IP\": \"195.221.65.187\"\n    },\n    {\n        \"IP\": \"223.215.140.121\"\n    },\n    {\n        \"IP\": \"42.254.253.187\"\n    },\n    {\n        \"IP\": \"99.236.88.173\"\n    },\n    {\n        \"IP\": \"87.49.237.85\"\n    },\n    {\n        \"IP\": \"124.230.221.226\"\n    },\n    {\n        \"IP\": \"46.22.123.116\"\n    },\n    {\n        \"IP\": \"105.85.140.56\"\n    },\n    {\n        \"IP\": \"69.167.167.233\"\n    },\n    {\n        \"IP\": \"176.44.47.123\"\n    },\n    {\n        \"IP\": \"40.225.1.63\"\n    },\n    {\n        \"IP\": \"102.209.225.101\"\n    },\n    {\n        \"IP\": \"62.173.169.38\"\n    },\n    {\n        \"IP\": \"51.133.22.72\"\n    },\n    {\n        \"IP\": \"31.129.69.30\"\n    },\n    {\n        \"IP\": \"194.133.28.78\"\n    },\n    {\n        \"IP\": \"9.243.223.78\"\n    },\n    {\n        \"IP\": \"185.107.13.97\"\n    },\n    {\n        \"IP\": \"155.131.137.219\"\n    }\n]\n```\n\n测试输出：\n\n```\n\n\n\nSummary:\n  Count:        1200\n  Total:        36.67 s\n  Slowest:      19.65 s\n  Fastest:      1.01 s\n  Average:      11.12 s\n  Requests/sec: 32.72\n\nResponse time histogram:\n  1011.354 [1]  |\n  2875.261 [8]  |∎\n  4739.167 [13] |∎\n  6603.074 [17] |∎∎\n  8466.981 [230]        |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  10330.887 [117]       |∎∎∎∎∎∎∎∎∎∎∎\n  12194.794 [440]       |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  14058.701 [172]       |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  15922.608 [145]       |∎∎∎∎∎∎∎∎∎∎∎∎∎\n  17786.514 [44]        |∎∎∎∎\n  19650.421 [7] |∎\n\nLatency distribution:\n  10%% in 8.15 s\n  25%% in 9.21 s\n  50%% in 11.17 s\n  75%% in 12.50 s\n  90%% in 14.51 s\n  95%% in 15.28 s\n  99%% in 17.24 s\n\nStatus code distribution:\n  [OK]                 1194 responses\n  [DeadlineExceeded]   6 responses\n\nError distribution:\n  [5]   rpc error: code = DeadlineExceeded desc = context deadline exceeded\n  [1]   rpc error: code = DeadlineExceeded desc = Deadline Exceeded\n```\n测试输出提示请求超时，而且大量请求响应时间很不理想，查看日志发现StackExchange.Redis.RedisTimeoutException异常：\n\n\n```\nStackExchange.Redis.RedisTimeoutException: Timeout performing EVAL, inst: 5, queue: 1032, qu: 0, qs: 1032, qc: 0, wr: 0, wq: 0, in: 97489, ar: 0, clientName: , serverEndpoint: 192.168.1.44:43667, keyHashSlot: 693 (Please take a look at this article for some common client-side issues that can cause timeouts: http:\\/\\/stackexchange.github.io\\/StackExchange.Redis\\/Timeouts)\\n   at StackExchange.Redis.ConnectionMultiplexer.ExecuteSyncImpl[T](Message message, ResultProcessor`1 processor, ServerEndPoint server ...\n```\n## 问题解决\n根据[StackExchange.Redis官方文档](https://github.com/StackExchange/StackExchange.Redis/blob/master/docs/Timeouts.md)描述,在高并发场景下，当StackExchange.Redis的内部线程池无法满足并发要求的时候会去请求CLR的全局线程池，全局线程池的初始线程数量是根据CPU的核心数来确定的，当全局线程池的线程不够用的时候，会以500ms/per thread的速度往线程池里面添加新的线程，但这个速度在高并发场景下还是远远不够的，为此需要配置CLR线程池的最小线程数来满足高并发的场景。\n在程序入口添加如下代码：\n\n```\nThreadPool.SetMinThreads(512, 100) //worker最小线程数512,IOCP最小线程数100\n```\n\n\n## 问题验证\n配置最小线程数后再进行压力测试，测试输出如下：\n\n```\nSummary:\n  Count:        1200\n  Total:        2.66 s\n  Slowest:      2.15 s\n  Fastest:      1.99 ms\n  Average:      827.12 ms\n  Requests/sec: 451.92\n\nResponse time histogram:\n  1.987 [1]     |\n  216.449 [66]  |∎∎∎∎∎∎∎\n  430.911 [174] |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  645.373 [403] |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  859.835 [136] |∎∎∎∎∎∎∎∎∎∎∎∎∎\n  1074.297 [75] |∎∎∎∎∎∎∎\n  1288.759 [48] |∎∎∎∎∎\n  1503.221 [69] |∎∎∎∎∎∎∎\n  1717.683 [156]        |∎∎∎∎∎∎∎∎∎∎∎∎∎∎∎\n  1932.145 [13] |∎\n  2146.607 [59] |∎∎∎∎∎∎\n\nLatency distribution:\n  10%% in 332.77 ms\n  25%% in 445.91 ms\n  50%% in 547.70 ms\n  75%% in 1.28 s\n  90%% in 1.68 s\n  95%% in 1.91 s\n  99%% in 2.11 s\n\nStatus code distribution:\n  [OK]   1200 responses\n\n```\n超时问题消失,并且响应时间大幅度减小\n\n\n需要注意的是，如果机器配置不够（CPU跑满了)，再高并发场景下，仍然会出现超时问题。\n\n\n"},{"title":"记线上的一次Mysql死锁问题分析","url":"/2020/03/14/记线上的一次Mysql死锁问题分析/","content":"\n## 问题描述\n最近上线了叫做“F币”的功能，简单说下就是系统会根据用户每天在社区的活跃行为，计算每一个用户的活跃度，最后根据用户每天的总活跃度返还相应的“F币”给用户，用户得到F币之后可以在社区兑换不同的礼品,如下图所示：\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/BF0B1ABB-F459-4343-BE90-5177FB6583D5.png)\n\n在测试环境和仿真环境运行的好好的，但是上线之后经常接到用户反馈，需要多次点击才能完成领取。查看阿里云日志，提示数据库产生死锁，如下图所示：\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/9DF85AF7-0840-4323-9B0C-613480533A45.png)\n\n## 问题分析\n注意到这里有一排按钮，用户的每次点击，后台都会进行以下两个操作：\n1. 更新用户余额（用户表）\n2. 生成流水记录 （用户流水记录）\n\n注：用户表和流水表存在主外键关系\n\n以上的两个操作会放在同一个事务完成，并且由于Ef的SaveChanges并不会根据你代码执行的先后次序去更新数据库，当用户以很快的速度从左到右依次点击，存在以下可能：\n\nT1:事务A插入流水，由于存在外键，会对user对应的行上S锁。\n\nT2:事务B插入流水，由于存在外键，会对user对应的行上S锁。\n\nT3:事务A更新User的余额，请求行记录的X锁，被B事务在T2的S锁阻塞\n\nT4:事务B更新User的余额，请求行记录的X锁，被A事务在T1的S锁阻塞\n\n至此死锁产生。\n\n\n\n## 问题解决\n\n用了一个比较简单+暴力的方法：领取接口直接上redis分布式锁。\n\n\n## 总结与反思\n\n这个项目是使用DDD的思想进行开发的，自然而然地在ORM上面的选型使用了EntityFramework Code First,但是Code Firit在建表的时候会自做主张的在“多”端生成外键。对外键的使用，除开了一部分性能开销，就是上述的死锁问题，后续考虑把这部分重构为DbFirst。\n\n另外值得一提的是，后来对这部逻辑做了压测，发现这部分代码在Sql Server跑是没问题的，因为Sql Server在插入子表的时候不会对父表记录上锁，而Mysql会对父表上锁,所以产生了死锁，天下果然没有免费午餐！\n\n\n\n## 参考\n\n\n[DbContext SaveChanges Order of Statement Execution\n](https://stackoverflow.com/questions/7335582/dbcontext-savechanges-order-of-statement-execution)\n\n[Deadlock due to Foreign Key constraint](https://bugs.mysql.com/bug.php?id=48652)"},{"title":"AspNetCore2.1升级到3.1时CORS相关配置的变更","url":"/2020/02/27/AspNetCore2.1升级到3.1时CORS相关配置的变更/","content":"\n本周将公司的运营系统从AspNetCore2.1升级到了AspNetCore3.1,遇到了一些坑，这里记录以下\n\n## 2.1的相关CORS代码\n\n\n```\npublic IServiceProvider ConfigureServices(IServiceCollection services)\n{\n\n        ... // 省略\n        services.AddCors(option => option.AddPolicy(\"corsPolicy\", builders =>\n        {\n            builders.AllowCredentials().AllowAnyOrigin().AllowAnyHeader().AllowAnyMethod();\n        }));\n        ... // 省略\n}\n\npublic void Configure(IApplicationBuilder app, ILoggerFactory loggerFactory, IHostingEnvironment env)\n{\n    ... // 省略\n    app.UseCors(\"corsPolicy\");\n     ... // 省略\n}\n```\n\n如果这部分代码这3.1的服务中不加任何修改，启动时提示错误：\n\n\n```\nThe CORS protocol does not allow specifying a wildcard (any) origin and credentials at the same time. Configure the CORS policy by listing individual origins if credentials needs to be supported.\n```\n\n\n这是由于在2.1之后,AspNetCore出于安全考虑，做了更加严格的限制，在不AllowCredentials()与AllowAnyOrigin()。\n\n假设现在站点A存在一个恶意脚本，而站点B存在一个比较的敏感的接口（如转账）。如果站点B作为服务端使用AllowCredentials()与AllowAnyOrigin()的同源配置，此时站点A可以直接调用站点B的敏感接口并发送凭证信息（如Cookie），那么将导致用户信息被窃取。\n\n\n\n## 3.1的相关CORS代码\n\n### options1 显示声明允许跨域的origin\n\n```\nservices.AddCors(option => option.AddPolicy(\"corsPolicy\", builders =>\n            {\n                builders.WithOrigins(\"http://site.com\").AllowAnyHeader().AllowAnyMethod().AllowCredentials();\n            }));\n```\n\n\n### options2 使用 SetIsOriginAllowed（可以起到与AllowAnyOriginu一样的效果）\n\n\n```\nservices.AddCors(option => option.AddPolicy(\"corsPolicy\", builders =>\n            {\n                builders.SetIsOriginAllowed(origin=>true).AllowAnyHeader().AllowAnyMethod().AllowCredentials(); //SetIsOriginAllowed(origin=>true)允许所有origin\n            }));\n```\n\n\n"},{"title":"InnodDB中的Gap Locks与Next-key Locks","url":"/2020/02/11/InnodDB中的Gap Locks与Next-key Locks/","content":"\n为了理解Gap Locks与Next-key Locks首先必须了解InnodDB定义的四种隔离级别\n\n## InnodDB的四种隔离级别\n\n1. Read uncommitted(未授权读取、读未提交)：如果一个事务已经开始写数据，则另外一个事务则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。这样就避免了更新丢失，却可能出现脏读。也就是说事务B读取到了事务A未提交的数据。\n2. Read committed（授权读取、读提交）： 读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。该隔离级别避免了脏读，但是却可能出现不可重复读。事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。\n3. Repeatable read（可重复读取,MySQL默认隔离级别）： 可重复读是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，即使第二个事务对数据进行修改，第一个事务两次读到的的数据是一样的。这样就发生了在一个事务内两次读到的数据是一样的，因此称为是可重复读。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。这样避免了不可重复读取和脏读，但是有时可能出现幻象读。（读取数据的事务）这可以通过“共享读锁”和“排他写锁”实现。\n4. Serializable（序列化）： 提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。序列化是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。 \n\n\n## Gap Locks\n如下图所示：假设存在一个索引(Key,pk),那么当innodb在一事务中中对(-∞,(9,5)]追加Gap Locks后,如果其他事务尝试在索引记录中的任意一个Gap添加记录,该事务将会被阻塞\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/WeChat%20Screenshot_20200217021548.png)\n\n## Next-key Locks\nNext-key Locks = Gap Locks + index-record lock。\n当在某一个事务中执行一个SELECT语句，Innodb会通过扫描相应的索引记录来找到生成一个ResultSet，这个时候被扫描到的索引记录都被被添加Next-key locks。\n举个例子，假设现在存在一张表T，T的主键为ID，ID的可能值是10，11，13，20。\n现在在一个事务中执行如下语句：\n\n```\nSELECT ID FROM T WHERE ID >=10 AND ID <= 20 FOR UPDATE;\n```\n\n这个时候会产生的Next-key Locks如下:\n\n```\n(-∞, 10]\n(10, 11]\n(11, 13]\n(13, 20]\n(20, +∞)\n```\n其他事务不能这个范围内将不能插入新的纪录（避免了幻读），也不能修改相应的记录（避免了不可重复读）\n\n可见Next-key Locks与Gap Locks主要是为了满足Repeatable read的一致性要求。\n\n另外值得注意的一点是，如果被扫描到的索引是一个唯一索引，且只有并且只有一笔记录，那么这个时候只会上index-record lock，因为这个时候其他事务产生了新的记录，也不会产生幻读。\n\n\n\n\n\n\n"},{"title":"Maven库配置阿里云加速","url":"/2020/01/19/Maven库配置阿里云加速/","content":"\n由于国内的网络原因,通过maven拉取相关package的时候总是特别慢，极大的影响到工作效率。所幸的是阿里云提供了maven库的镜像服务，体验了一下，速度飞快。配置方法如下：\n\n## Maven仓库配置阿里云加速\n- 确定settings.xml配置文件位置\n执行如下命令：\n\n```\nmvn -X\n```\n\n输入如下：\n\n```\n.....省略\n[DEBUG] Reading global settings from /usr/share/maven/conf/settings.xml\n[DEBUG] Reading user settings from /home/abc/.m2/settings.xml\n[DEBUG] Reading global toolchains from /usr/share/maven/conf/toolchains.xml\n[DEBUG] Reading user toolchains from /home/loremipsum/.m2/toolchains.xml\n[DEBUG] Using local repository at /home/abc/.m2/repository\n\n.....省略\n```\n\n- 修改settings.xml,修改mirrors xml结点下的相关配置\n\n```\n  <mirrors>\n    <!-- mirror\n     | Specifies a repository mirror site to use instead of a given repository. The repository that\n     | this mirror serves has an ID that matches the mirrorOf element of this mirror. IDs are used\n     | for inheritance and direct lookup purposes, and must be unique across the set of mirrors.\n     |\n    <mirror>\n      <id>mirrorId</id>\n      <mirrorOf>repositoryId</mirrorOf>\n      <name>Human Readable Name for this Mirror.</name>\n      <url>http://my.repository.com/repo/path</url>\n    </mirror>\n     -->\n    <mirror>\n      <id>aliyun-public</id>\n      <name>aliyun public</name>\n      <mirrorOf>public</mirrorOf>\n      <url>https://maven.aliyun.com/repository/public</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-central</id>\n      <name>aliyun central</name>\n      <mirrorOf>central</mirrorOf>\n      <url>https://maven.aliyun.com/repository/central</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-jcenter</id>\n      <name>aliyun jcenter</name>\n      <mirrorOf>jcenter</mirrorOf>\n      <url>https://maven.aliyun.com/repository/jcenter</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-spring</id>\n      <name>aliyun spring</name>\n      <mirrorOf>spring</mirrorOf>\n      <url>https://maven.aliyun.com/repository/spring</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-spring-milestones</id>\n      <name>aliyun spring milestones</name>\n      <mirrorOf>spring-milestones</mirrorOf>\n      <url>https://maven.aliyun.com/repository/spring</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-spring-plugin</id>\n      <name>aliyun spring plugin</name>\n      <mirrorOf>spring-plugin</mirrorOf>\n      <url>https://maven.aliyun.com/repository/spring-plugin</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-gradle-plugin</id>\n      <name>aliyun gradle plugin</name>\n      <mirrorOf>gradle-plugin</mirrorOf>\n      <url>https://maven.aliyun.com/repository/gradle-plugin</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-google</id>\n      <name>aliyun google</name>\n      <mirrorOf>google</mirrorOf>\n      <url>https://maven.aliyun.com/repository/google</url>\n    </mirror>\n\n    <mirror>\n      <id>aliyun-grails-core</id>\n      <name>aliyun grails core</name>\n      <mirrorOf>grails-core</mirrorOf>\n      <url>https://maven.aliyun.com/repository/grails-core</url>\n    </mirror>\n</mirrors>\n\n```\n\n## 防坑：\n大部分的包阿里云的maven镜像库都有，一部分比较新的库上面是没有的，如springboot，阿里云上面的版本只是到了2.2.0，实际2.2.4都已经出来了，同步不是很及时。目前我都一些没有的库做了降级处理，后续再看看怎么处理这个问题\n"},{"title":"Kafka连接超时问题的本质","url":"/2020/01/15/Kafka连接超时问题的本质/","content":"## 问题的背景\n前段时间开发环境搭建了一套kafka环境，搭建完成后通过客户端去连接kafka时，当produer调用send的时候程序都会直接hang住，提示连接超时：\n\n```\norg.apache.kafka.common.errors.TimeoutException: \nExpiring 1 record(s) for demo-topic-0:120000 ms has passed since batch creation\n```\n接着我试了一下调用producer的partitionsFor方法，可以正常执行。同样的，当consumer执行poll方法时，程序也会直接卡死。\n\n## 问题的本质\nproducer是通过leader broker往partition写入数据,当producer希望写入数据的时候会向kafka请求当前的leader broker信息，这个时候如果kafka的leader broker的host信息如果和客户端不在同一个网段就会出现上述的超时现象，这也就可以解释为什么partitionsFor方法可以正常执行(不涉及到leader broker的通信)，但是send方法(涉及到leader broker的通信)执行失败。\n\n\n## 问题解决\n\n配置ADVERTISED_HOST\n\n\n```\nbash-4.4# vi $KAFKA_HOME/config/server.properties\n```\n\n这里我的配置是\n\n```\nadvertised.listeners=PLAINTEXT://127.0.0.1:9092\n```\n\n由于是使用docker部署，客户端和服务端不在同一台机器上，所以我需要把这个配置改为与客户端同一个网段的\n\n\n## 问题验证\n\n当ADVERTISED_HOST为PLAINTEXT://127.0.0.1:9092可以看到partitionsFor返回的leader broker信息为下图所示：\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/CD584EBE-9DDF-4bbb-AF15-7970A064979A.png)\n\n修改ADVERTISED_HOST后，返回信息如下：\n![](https://raw.githubusercontent.com/LoremipsumSharp/Images/master/img/53CA72B0-F276-4ef7-B524-18C970ED3443.png)\n\n\n没有再次出现连接超时的问题\n\n\n## 参考\n[kafka-listeners-explained](https://rmoff.net/2018/08/02/kafka-listeners-explained/)\n\n[Client and broker compatibility across Kafka versions](https://docs.cloudera.com/runtime/7.1.0/kafka-managing/topics/kafka-manage-client-broker-comp.html)"},{"title":"NetCore应用配置Auto Core Dump","url":"/2020/01/09/NetCore应用配置Auto Core Dump/","content":"\n## 问题背景\n前阵子线上用户标签服务频繁出现内存泄漏问题，早上服务运行的好好的，经常一到半夜服务就挂掉。由于事发半夜，很难加以人工干预，而早上dump出来的文件参考价值很低，迫切需要一种自动化的手段让服务在宕掉的时候能够保存完整的案发现场。事实上，.NET CORE可以支持这一需求，不过默认是不开启的，需要加以配置。\n\n## Auto Core Dump配置方法\n\n以下内容是我原封不动从dotnet/rumtime这个仓库拷贝过来的：\n\nEnvironment variables supported:\n\n- `COMPlus_DbgEnableMiniDump`: if set to \"1\", enables this core dump generation. The default is NOT to generate a dump.\n- `COMPlus_DbgMiniDumpType`: See below. Default is \"2\" MiniDumpWithPrivateReadWriteMemory.\n- `COMPlus_DbgMiniDumpName`: if set, use as the template to create the dump path and file name. The pid can be placed in the name with %d. The default is _/tmp/coredump.%d_.\n- `COMPlus_CreateDumpDiagnostics`: if set to \"1\", enables the _createdump_ utilities diagnostic messages (TRACE macro).\n\nCOMPlus_DbgMiniDumpType values:\n\n\n|Value|Minidump Enum|Description|\n|-|:----------:|----------|\n|1| MiniDumpNormal                               | Include just the information necessary to capture stack traces for all existing threads in a process. Limited GC heap memory and information. |\n|2| MiniDumpWithPrivateReadWriteMemory (default) | Includes the GC heaps and information necessary to capture stack traces for all existing threads in a process. |\n|3| MiniDumpFilterTriage                         | Include just the information necessary to capture stack traces for all existing threads in a process. Limited GC heap memory and information. |\n|4| MiniDumpWithFullMemory                       | Include all accessible memory in the process. The raw memory data is included at the end, so that the initial structures can be mapped directly without the raw memory information. This option can result in a very large file. |\n\n\n根据以上内容，可以在Dockerfile或者docker-compose文件加入以下环境变量\n\n```\nENV COMPlus_DbgEnableMiniDump=\"1\"  # enables core dump generation\nENV COMPlus_DbgMiniDumpName=\"/diagnostics/dumps/coredump_%d\" # core dump文件位置，一般是一个挂在在宿主机的目录\nENV COMPlus_DbgMiniDumpType=\"4\" # 建议选择4，也就是full dump，保存的“现场”更加完整，但文件也会非常大\n```\n\n\n## 实验\n\n在一个可以被调用的接口加入以下代码：\n\n```\nEnvironment.FailFast()\n```\n这个方法可以让应用直接挂掉,挂掉后观察相应的挂载目录有无生成dump文件\n\n\n\n## 参考\n\n[xplat-minidump-generation](https://github.com/dotnet/runtime/blob/8497763bbfa70455e6f08ed7aa345d43db1d22d7/docs/design/coreclr/botr/xplat-minidump-generation.md)"}]